{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ii069NmDFT8u","outputId":"cb2f98a1-80ad-4f87-9e88-bd6b8627fe8d","executionInfo":{"status":"ok","timestamp":1669032895592,"user_tz":300,"elapsed":7416,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.7.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install transformers\n","!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PIYgmK7JGApG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669032896431,"user_tz":300,"elapsed":844,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"611d918d-d516-4974-f980-4906a1ecdebc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["foldername= \"/content/drive/My Drive/nlpproject/\""],"metadata":{"id":"SO5mqsc8ZeJz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndair6dzFBl1"},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from transformers import DataCollatorWithPadding\n","from transformers import TrainingArguments, Trainer\n","from datasets import load_metric\n","import datetime\n","from torch import nn\n","from transformers import AutoConfig\n","from transformers import AutoModel\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_B13Be1POha"},"outputs":[],"source":["class CFG:\n","    str_now = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n","    basic_lr=1e-3\n","    train = True\n","    debug = False\n","    offline = False\n","    models_path = \"bert-base-uncased\"\n","    epochs = 50\n","    save_all_models = False\n","    apex = True\n","    print_freq = 20\n","    num_workers = 4\n","    model = \"bert-base-uncased\"\n","    loss_func = 'SmoothL1'\n","    scheduler = 'cosine'\n","    batch_scheduler = True\n","    num_cycles = 0.5\n","    num_warmup_steps = 0\n","    encoder_lr = 2e-5\n","    decoder_lr = 2e-5\n","    min_lr = 1e-6\n","    llrd = True\n","    layerwise_lr = 5e-5\n","    layerwise_lr_decay = 0.9\n","    layerwise_weight_decay = 0.01\n","    layerwise_adam_epsilon = 1e-6\n","    layerwise_use_bertadam = False\n","    #pooling\n","    pooling = 'mean' # mean, max, min, attention, weightedlayer\n","    layer_start = 4\n","    #init_weight\n","    init_weight = 'normal' # normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal\n","    #re-init\n","    reinit = True\n","    reinit_n = 1\n","    #adversarial\n","    fgm = False\n","    awp = False\n","    adv_lr = 1\n","    adv_eps = 0.2\n","    unscale = False\n","    eps = 1e-6\n","    betas = (0.9, 0.999)\n","    max_len = 512\n","    weight_decay = 0.01\n","    gradient_accumulation_steps = 1\n","    max_grad_norm = 1000\n","    target_cols = ['EI', 'SN', 'TF', 'JP']\n","    seed = 42\n","    cv_seed = 42\n","    n_fold = 4\n","    trn_fold = list(range(n_fold))\n","    batch_size = 128\n","    n_targets = 4\n","    gpu_id = 0\n","    device = f'cuda:{gpu_id}'\n","cfg=CFG()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcMZxYMsFBl4"},"outputs":[],"source":["\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification\n","tokenizer=BertTokenizer.from_pretrained(cfg.model)\n","#the dataset class for the first dataset, tokenized, and labeled\n","class Ds_EI(Dataset):\n","    def __init__(self, path, tokenizer, max_token_len=cfg.max_len):\n","        self.df = pd.read_csv(path).dropna()\n","        self.tokenizer=tokenizer\n","        self.max_token_len=max_token_len\n","        self.labelstrdicts={1:\"ESTJ\", 0:\"INFP\"}\n","        self.loc=0  #EI at index 0 in mbti\n","    def __len__(self):\n","        return (len(self.df))\n","    def __getitem__(self, index):\n","        item=self.df.iloc[index]\n","        text=item[\"post\"]\n","        type=item[\"type\"]\n","        labels=self.str2label(type)\n","        try:\n","          tokens=self.tokenizer(text,return_tensors=\"pt\", truncation=True, max_length=self.max_token_len, padding=\"max_length\")\n","        except:\n","          print(text)\n","          quit()\n","        return {\"input_ids\": torch.squeeze(tokens.input_ids), \"attention_mask\":torch.squeeze(tokens.attention_mask), \"labels\":labels}\n","    def str2label(self, string):\n","        letter=string[self.loc]\n","        if letter in \"ESTJ\":\n","            return 1.\n","        else:\n","            return 0.\n","    def label2str(self, label):\n","        return self.labelstrdicts[label][self.loc]\n","\n","class Ds_SN(Dataset):\n","    def __init__(self, path, tokenizer, max_token_len=cfg.max_len):\n","        self.df = pd.read_csv(path).dropna()\n","        self.tokenizer=tokenizer\n","        self.max_token_len=max_token_len\n","        self.labelstrdicts={1:\"ESTJ\", 0:\"INFP\"}\n","        self.loc=1  #EI at index 0 in mbti\n","    def __len__(self):\n","        return (len(self.df))\n","    def __getitem__(self, index):\n","        item=self.df.iloc[index]\n","        text=item[\"post\"]\n","        type=item[\"type\"]\n","        labels=self.str2label(type)\n","        try:\n","          tokens=self.tokenizer(text,return_tensors=\"pt\", truncation=True, max_length=self.max_token_len, padding=\"max_length\")\n","        except:\n","          print(text)\n","          quit()\n","        return {\"input_ids\": torch.squeeze(tokens.input_ids), \"attention_mask\":torch.squeeze(tokens.attention_mask), \"labels\":labels}\n","    def str2label(self, string):\n","        letter=string[self.loc]\n","        if letter in \"ESTJ\":\n","            return 1.\n","        else:\n","            return 0.\n","    def label2str(self, label):\n","        return self.labelstrdicts[label][self.loc]\n","\n","class Ds_TF(Dataset):\n","    def __init__(self, path, tokenizer, max_token_len=cfg.max_len):\n","        self.df = pd.read_csv(path).dropna()\n","        self.tokenizer=tokenizer\n","        self.max_token_len=max_token_len\n","        self.labelstrdicts={1:\"ESTJ\", 0:\"INFP\"}\n","        self.loc=2  #EI at index 0 in mbti\n","    def __len__(self):\n","        return (len(self.df))\n","    def __getitem__(self, index):\n","        item=self.df.iloc[index]\n","        text=item[\"post\"]\n","        type=item[\"type\"]\n","        labels=self.str2label(type)\n","        try:\n","          tokens=self.tokenizer(text,return_tensors=\"pt\", truncation=True, max_length=self.max_token_len, padding=\"max_length\")\n","        except:\n","          print(text)\n","          quit()\n","        return {\"input_ids\": torch.squeeze(tokens.input_ids), \"attention_mask\":torch.squeeze(tokens.attention_mask), \"labels\":labels}\n","    def str2label(self, string):\n","        letter=string[self.loc]\n","        if letter in \"ESTJ\":\n","            return 1.\n","        else:\n","            return 0.\n","    def label2str(self, label):\n","        return self.labelstrdicts[label][self.loc]\n","\n","class Ds_JP(Dataset):\n","    def __init__(self, path, tokenizer, max_token_len=cfg.max_len):\n","        self.df = pd.read_csv(path).dropna()\n","        self.tokenizer=tokenizer\n","        self.max_token_len=max_token_len\n","        self.labelstrdicts={1:\"ESTJ\", 0:\"INFP\"}\n","        self.loc=3  #EI at index 0 in mbti\n","    def __len__(self):\n","        return (len(self.df))\n","    def __getitem__(self, index):\n","        item=self.df.iloc[index]\n","        text=item[\"post\"]\n","        type=item[\"type\"]\n","        labels=self.str2label(type)\n","        try:\n","          tokens=self.tokenizer(text,return_tensors=\"pt\", truncation=True, max_length=self.max_token_len, padding=\"max_length\")\n","        except:\n","          print(text)\n","          quit()\n","        return {\"input_ids\": torch.squeeze(tokens.input_ids), \"attention_mask\":torch.squeeze(tokens.attention_mask), \"labels\":labels}\n","    def str2label(self, string):\n","        letter=string[self.loc]\n","        if letter in \"ESTJ\":\n","            return 1.\n","        else:\n","            return 0.\n","    def label2str(self, label):\n","        return self.labelstrdicts[label][self.loc]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddPb2H0pFBl7"},"outputs":[],"source":["path=foldername+\"dataset2(sep).csv\"\n","#print(dataset[0])\n","data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n","def getdl(ds):\n","    #total_len=len(ds)\n","    #train_len=int(len(ds)*0.8)\n","    #val_len=int((total_len-train_len)/2)\n","    #test_len=total_len-train_len-val_len\n","    #[train_ds, val_ds, test_ds]=torch.utils.data.random_split(ds, [train_len, val_len, test_len])\n","    #return (training dataloader, validation dataloader, test dataloader)\n","    #return DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=data_collator), DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=data_collator), DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=data_collator)\n","    return DataLoader(ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=data_collator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Y7Vn2lUl15T"},"outputs":[],"source":["#NEED TO CHANGE WHEN SWITCH TASK\n","ds=Ds_EI(path, tokenizer)\n","dl_EI=getdl(ds)"]},{"cell_type":"code","source":["config = AutoConfig.from_pretrained(CFG.model, ouput_hidden_states = True)\n","model = AutoModel.from_pretrained(CFG.model, config=config)\n","model.requires_grads=False"],"metadata":{"id":"1EFcPfuA90hG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669032903628,"user_tz":300,"elapsed":1844,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"fd006ff7-2395-4862-9304-94ad20146d9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["if torch.cuda.is_available():  \n","    dev = \"cuda:0\" \n","else:  \n","    dev = \"cpu\" \n","device = torch.device(dev)\n","cpu=torch.device(\"cpu\")\n","features=[]\n","labels=[]\n","model.to(device)\n","with torch.no_grad():\n","    for i,batch in enumerate(dl_EI):\n","        print(i*cfg.batch_size)\n","        batch.to(device)\n","        #last_hidden_layers=model(input_ids=batch[\"input_ids\"],attention_mask=batch[\"attention_mask\"]).last_hidden_state[:,0]\n","        #last_hidden_layers.to(\"cpu\")\n","        #features.extend(last_hidden_layers)\n","        output=model(input_ids=batch[\"input_ids\"],attention_mask=batch[\"attention_mask\"])\n","        #print(output)\n","        pooler_output=output.pooler_output\n","        pooler_output=pooler_output.to(cpu)\n","        #print(pooler_output[0])\n","        features.extend(pooler_output)\n","        l=batch[\"labels\"].to(\"cpu\")\n","        labels.extend(l)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xyexQtxY1TE1","executionInfo":{"status":"ok","timestamp":1669033301913,"user_tz":300,"elapsed":398289,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"0e0fcdd3-96c6-4693-f9a6-2dc2802758b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","128\n","256\n","384\n","512\n","640\n","768\n","896\n","1024\n","1152\n","1280\n","1408\n","1536\n","1664\n","1792\n","1920\n","2048\n","2176\n","2304\n","2432\n","2560\n","2688\n","2816\n","2944\n","3072\n","3200\n","3328\n","3456\n","3584\n","3712\n","3840\n","3968\n","4096\n","4224\n","4352\n","4480\n","4608\n","4736\n","4864\n","4992\n","5120\n","5248\n","5376\n","5504\n","5632\n","5760\n","5888\n","6016\n","6144\n","6272\n","6400\n","6528\n","6656\n","6784\n","6912\n","7040\n","7168\n","7296\n","7424\n","7552\n","7680\n","7808\n","7936\n","8064\n","8192\n","8320\n","8448\n","8576\n"]}]},{"cell_type":"code","source":["features=torch.stack(features)\n","labels=torch.stack(labels)"],"metadata":{"id":"92cYKlop9l6P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(features, foldername+'EI_Extraced_feature_tensors_pooleroutput.pt')\n","torch.save(labels, foldername+'EI_Extraced_label_tensors_pooleroutput.pt')"],"metadata":{"id":"lBBbSgR11ugm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f=torch.load(foldername+'EI_Extraced_feature_tensors_pooleroutput.pt')"],"metadata":{"id":"GHVmLJgs-pMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(f[0]==features[0])"],"metadata":{"id":"oREM_Q0A-0b4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669033366616,"user_tz":300,"elapsed":125,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"e9dce383-372b-4c06-bb21-b84b98ddfff9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True])"]},"metadata":{},"execution_count":18}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"machine_shape":"hm"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"vscode":{"interpreter":{"hash":"47e86d731e077963188d400b641a1f5cee6401b89b8a1175acb1a082248e2517"}}},"nbformat":4,"nbformat_minor":0}