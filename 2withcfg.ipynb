{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7298,
     "status": "ok",
     "timestamp": 1668378969268,
     "user": {
      "displayName": "Riteng Zhang",
      "userId": "02510405192248153233"
     },
     "user_tz": 300
    },
    "id": "Ii069NmDFT8u",
    "outputId": "ee6c3396-78cd-47a9-9d4b-29d8253e058b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
      "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1525,
     "status": "ok",
     "timestamp": 1668378970785,
     "user": {
      "displayName": "Riteng Zhang",
      "userId": "02510405192248153233"
     },
     "user_tz": 300
    },
    "id": "PIYgmK7JGApG",
    "outputId": "ea2beaa6-747c-4af6-c4bb-b1ce034e08b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1668378970786,
     "user": {
      "displayName": "Riteng Zhang",
      "userId": "02510405192248153233"
     },
     "user_tz": 300
    },
    "id": "ndair6dzFBl1"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "import datetime\n",
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1668378970786,
     "user": {
      "displayName": "Riteng Zhang",
      "userId": "02510405192248153233"
     },
     "user_tz": 300
    },
    "id": "6_B13Be1POha"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    str_now = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    train = True\n",
    "    debug = False\n",
    "    offline = False\n",
    "    models_path = \"bert-base-uncased\"\n",
    "    epochs = 5\n",
    "    save_all_models = False\n",
    "    apex = True\n",
    "    print_freq = 20\n",
    "    num_workers = 4\n",
    "    model = \"bert-base-uncased\"\n",
    "    loss_func = 'SmoothL1'\n",
    "    scheduler = 'cosine'\n",
    "    batch_scheduler = True\n",
    "    num_cycles = 0.5\n",
    "    num_warmup_steps = 0\n",
    "    encoder_lr = 2e-5\n",
    "    decoder_lr = 2e-5\n",
    "    min_lr = 1e-6\n",
    "    llrd = True\n",
    "    layerwise_lr = 5e-5\n",
    "    layerwise_lr_decay = 0.9\n",
    "    layerwise_weight_decay = 0.01\n",
    "    layerwise_adam_epsilon = 1e-6\n",
    "    layerwise_use_bertadam = False\n",
    "    #pooling\n",
    "    pooling = 'mean' # mean, max, min, attention, weightedlayer\n",
    "    layer_start = 4\n",
    "    #init_weight\n",
    "    init_weight = 'normal' # normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal\n",
    "    #re-init\n",
    "    reinit = True\n",
    "    reinit_n = 1\n",
    "    #adversarial\n",
    "    fgm = False\n",
    "    awp = False\n",
    "    adv_lr = 1\n",
    "    adv_eps = 0.2\n",
    "    unscale = False\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    max_len = 50\n",
    "    weight_decay = 0.01\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "    target_cols = ['EI', 'SN', 'TF', 'JP']\n",
    "    seed = 42\n",
    "    cv_seed = 42\n",
    "    n_fold = 4\n",
    "    trn_fold = list(range(n_fold))\n",
    "    batch_size = 50\n",
    "    n_targets = 4\n",
    "    gpu_id = 0\n",
    "    device = f'cuda:{gpu_id}'\n",
    "cfg=CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1668378971218,
     "user": {
      "displayName": "Riteng Zhang",
      "userId": "02510405192248153233"
     },
     "user_tz": 300
    },
    "id": "tcMZxYMsFBl4"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "tokenizer=BertTokenizer.from_pretrained(cfg.model)\n",
    "#the dataset class for the first dataset, tokenized, and labeled\n",
    "class Ds1(Dataset):\n",
    "    def __init__(self, path, tokenizer, max_token_len=cfg.max_len):\n",
    "        self.df = pd.read_csv(path).dropna()\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_token_len=max_token_len\n",
    "        self.labelstrdicts={1:\"ESTJ\", 0:\"INFP\"}\n",
    "    def __len__(self):\n",
    "        return (len(self.df))\n",
    "    def __getitem__(self, index):\n",
    "        item=self.df.iloc[index]\n",
    "        text=item[\"post\"]\n",
    "        type=item[\"type\"]\n",
    "        labels=self.str2label(type)\n",
    "        try:\n",
    "          tokens=self.tokenizer(text,return_tensors=\"pt\", truncation=True, max_length=self.max_token_len, padding=\"max_length\")\n",
    "        except:\n",
    "          print(text)\n",
    "          quit()\n",
    "        return {\"input_ids\": torch.squeeze(tokens.input_ids), \"attention_mask\":torch.squeeze(tokens.attention_mask), \"labels\":labels}\n",
    "    def str2label(self, string):\n",
    "        label=[]\n",
    "        for letter in string:\n",
    "            if letter in \"ESTJ\":\n",
    "                label.append(1.)\n",
    "            else:\n",
    "                label.append(0.)\n",
    "        return label\n",
    "    def label2str(self, label):\n",
    "        string=[]\n",
    "        for index,number in enumerate(label):\n",
    "            string.append(self.labelstrdicts[number][index])\n",
    "        return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1794,
     "status": "ok",
     "timestamp": 1668378973011,
     "user": {
      "displayName": "Riteng Zhang",
      "userId": "02510405192248153233"
     },
     "user_tz": 300
    },
    "id": "ddPb2H0pFBl7"
   },
   "outputs": [],
   "source": [
    "path=\"/content/drive/MyDrive/nlpproject/dataset2.csv\"\n",
    "dataset=Ds1(path, tokenizer)\n",
    "#print(dataset[0])\n",
    "data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "def getdl(ds):\n",
    "    total_len=len(ds)\n",
    "    train_len=int(len(ds)*0.8)\n",
    "    val_len=int((total_len-train_len)/2)\n",
    "    test_len=total_len-train_len-val_len\n",
    "    [train_ds, val_ds, test_ds]=torch.utils.data.random_split(ds, [train_len, val_len, test_len])\n",
    "    #return (training dataloader, validation dataloader, test dataloader)\n",
    "    return DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=data_collator), DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=data_collator), DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=data_collator)\n",
    "train_dl, val_dl, test_dl=getdl(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1668378973011,
     "user": {
      "displayName": "Riteng Zhang",
      "userId": "02510405192248153233"
     },
     "user_tz": 300
    },
    "id": "qSy4KGQaFBl9"
   },
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self, CFG, pretrained = True):\n",
    "        super().__init__()\n",
    "        self.CFG = CFG\n",
    "        self.config = AutoConfig.from_pretrained(CFG.model, ouput_hidden_states = True)\n",
    "        self.config.hidden_dropout = 0.\n",
    "        self.config.hidden_dropout_prob = 0.\n",
    "        self.config.attention_dropout = 0.\n",
    "        self.config.attention_probs_dropout_prob = 0.\n",
    "        self.config.max_length=self.CFG.max_len\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(CFG.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)            \n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.CFG.n_targets)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "        if 'bert-base' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:12].requires_grad_(False)\n",
    "        \n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
    "                \n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
    "                \n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        feature = self.model(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"]).last_hidden_state[:,0]\n",
    "        fourlogits = self.fc(feature)\n",
    "        output = self.sig(fourlogits)\n",
    "        return output #4 number between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1668379140567,
     "user": {
      "displayName": "Riteng Zhang",
      "userId": "02510405192248153233"
     },
     "user_tz": 300
    },
    "id": "fJUdV0euFBl-"
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "def train(train_ds, eval_ds, model, epochs):\n",
    "    if torch.cuda.is_available():  \n",
    "        dev = \"cuda:0\" \n",
    "    else:  \n",
    "        dev = \"cpu\" \n",
    "    device = torch.device(dev)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "    scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=500, \n",
    "                                                                 eta_min=1e-6)\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        totaltrainloss=0\n",
    "        for i,batch in enumerate(train_ds):\n",
    "            #if i%100==0:\n",
    "              #print(i)\n",
    "            batch.to(device)\n",
    "            labels=batch[\"labels\"]\n",
    "            outputs=model(inputs=batch)\n",
    "            bloss=criterion(outputs, labels)\n",
    "            totaltrainloss+=bloss.item()\n",
    "            model.zero_grad()\n",
    "            bloss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        totalevalloss=0\n",
    "        with torch.no_grad():\n",
    "            for batch in eval_ds:\n",
    "                batch.to(device)\n",
    "                labels=batch[\"labels\"]\n",
    "                outputs=model(inputs=batch)\n",
    "                eloss=criterion(outputs, labels).item()\n",
    "                totalevalloss+=eloss\n",
    "        print(f'Epoch: {e+ 1} | Train Loss: {totaltrainloss / len(train_ds): .3f} | Val Loss: {totalevalloss / len(eval_ds): .3f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1963,
     "status": "ok",
     "timestamp": 1668379148560,
     "user": {
      "displayName": "Riteng Zhang",
      "userId": "02510405192248153233"
     },
     "user_tz": 300
    },
    "id": "vCSoyiclG2w3",
    "outputId": "8bed5083-e945-4d89-a8db-21dcffecc33f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model=myModel(cfg, pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1668379149267,
     "user": {
      "displayName": "Riteng Zhang",
      "userId": "02510405192248153233"
     },
     "user_tz": 300
    },
    "id": "9ONIKRdxIOv_"
   },
   "outputs": [],
   "source": [
    "for i in train_dl:\n",
    "  #print(i)\n",
    "  #print(model(inputs=i))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtdE1ZeaFBl_",
    "outputId": "d5a2f97b-2cc2-4bc9-9e7d-e6634513896b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss:  1.613 | Val Loss:  1.590\n",
      "Epoch: 2 | Train Loss:  1.586 | Val Loss:  1.586\n",
      "Epoch: 3 | Train Loss:  1.584 | Val Loss:  1.585\n",
      "Epoch: 4 | Train Loss:  1.583 | Val Loss:  1.584\n",
      "Epoch: 5 | Train Loss:  1.582 | Val Loss:  1.583\n",
      "Epoch: 6 | Train Loss:  1.581 | Val Loss:  1.582\n",
      "Epoch: 7 | Train Loss:  1.581 | Val Loss:  1.582\n"
     ]
    }
   ],
   "source": [
    "train(train_dl, val_dl, model, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "47e86d731e077963188d400b641a1f5cee6401b89b8a1175acb1a082248e2517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
