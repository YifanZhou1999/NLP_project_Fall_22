{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1778,"status":"ok","timestamp":1669863548553,"user":{"displayName":"Qingwan Cheng","userId":"11348850375708644329"},"user_tz":300},"id":"drh-27y0P52u","outputId":"abcb3cf5-c157-4ef4-b1ea-0e2f756e5071"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20344,"status":"ok","timestamp":1669863568890,"user":{"displayName":"Qingwan Cheng","userId":"11348850375708644329"},"user_tz":300},"id":"bNzkjH7-P0HD","outputId":"e9060203-5431-4e10-db85-709a2c6058dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.24.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.7.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.8/dist-packages (0.3.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.1.0)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.7.1)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n"]}],"source":["!pip install transformers\n","!pip install datasets\n","!pip install evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYzjfZHxP69V"},"outputs":[],"source":["#foldername= \"/content/drive/My Drive/nlpproject/bertsequenceclassification/\"\n","foldername= \"/content/drive/My Drive/Project/extractedfeaturewithbert/\"\n","#foldername= \"/content/drive/My Drive/extractedfeaturewithbert/\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZguGQVMP8J9"},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from transformers import DataCollatorWithPadding\n","from transformers import TrainingArguments, Trainer\n","from datasets import load_metric\n","import datetime\n","from torch import nn\n","from transformers import AutoConfig\n","from transformers import AutoModel\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","#import keras\n","#from keras.models import Model\n","#import keras.backend as K\n","#from keras.callbacks import ModelCheckpoint\n","#from keras.models import load_model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWp9GiTPP9UU"},"outputs":[],"source":["class CFG():\n","  max_len = 50\n","  #model = \"bert-base-uncased\"\n","  model = \"distilbert-base-uncased\"\n","  lr=1e-4\n","  min_lr=1e-10\n","  batch_size=16\n","  epoch=1000\n","  embedding_dim=512\n","  hidden_dim=256\n","  drop=0.15\n","cfg=CFG()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZ-y7ugzP-vV"},"outputs":[],"source":["class Ds(Dataset):\n","    def __init__(self, path, tokenizer, i, max_token_len=cfg.max_len):\n","        self.df = pd.read_csv(path).dropna()\n","        self.tokenizer=tokenizer\n","        self.max_token_len=max_token_len\n","        self.labelstrdicts={1:\"ESTJ\", 0:\"INFP\"}\n","        self.loc=i #EI at index 0 in mbti\n","    def __len__(self):\n","        return (len(self.df))\n","    def __getitem__(self, index):\n","        item=self.df.iloc[index]\n","        text=item[\"post\"]\n","        t=item[\"type\"]\n","        labels=self.str2label(t)\n","        try:\n","          tokens=self.tokenizer(text,return_tensors=\"pt\", truncation=True, max_length=self.max_token_len, padding=\"max_length\")\n","        except:\n","          print(text)\n","          quit()\n","        return {\"input_ids\": torch.squeeze(tokens.input_ids), \"attention_mask\":torch.squeeze(tokens.attention_mask), \"labels\":labels}\n","    def str2label(self, string):\n","        letter=string[self.loc]\n","        if letter in \"ESTJ\":\n","            return 1\n","        else:\n","            return 0\n","    def label2str(self, label):\n","        return self.labelstrdicts[label][self.loc]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2668,"status":"ok","timestamp":1669863571891,"user":{"displayName":"Qingwan Cheng","userId":"11348850375708644329"},"user_tz":300},"id":"GqOkdZKoQy7u","outputId":"1f480dd8-84e7-4033-fa04-e379b7cb19e1"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.24.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.24.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","#tokenizer = BertTokenizer.from_pretrained(cfg.model)\n","tokenizer = DistilBertTokenizer.from_pretrained(cfg.model)\n","config = AutoConfig.from_pretrained(cfg.model)\n","#bertmodel= BertForSequenceClassification.from_pretrained(cfg.model, config=config)\n","distilbertmodel= DistilBertForSequenceClassification.from_pretrained(cfg.model, config=config)\n","#bertmodel = AutoModelForSequenceClassification.from_pretrained(model_path)"]},{"cell_type":"code","source":["for name, param in distilbertmodel.named_parameters():\n","  print(name)\n","  if name.startswith('distilbert.transformer.layer.5'):\n","    param.requires_grad = True\n","  else:\n","    if name.startswith('distilbert.transformer.layer.')\n","      param.requires_grad = False\n","    else:\n","      param.requires_grad = True\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"becCb3mvmMTq","executionInfo":{"status":"ok","timestamp":1669863571891,"user_tz":300,"elapsed":11,"user":{"displayName":"Qingwan Cheng","userId":"11348850375708644329"}},"outputId":"d9a957cd-6665-4df4-b724-e10405991167"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["distilbert.embeddings.word_embeddings.weight\n","distilbert.embeddings.position_embeddings.weight\n","distilbert.embeddings.LayerNorm.weight\n","distilbert.embeddings.LayerNorm.bias\n","distilbert.transformer.layer.0.attention.q_lin.weight\n","distilbert.transformer.layer.0.attention.q_lin.bias\n","distilbert.transformer.layer.0.attention.k_lin.weight\n","distilbert.transformer.layer.0.attention.k_lin.bias\n","distilbert.transformer.layer.0.attention.v_lin.weight\n","distilbert.transformer.layer.0.attention.v_lin.bias\n","distilbert.transformer.layer.0.attention.out_lin.weight\n","distilbert.transformer.layer.0.attention.out_lin.bias\n","distilbert.transformer.layer.0.sa_layer_norm.weight\n","distilbert.transformer.layer.0.sa_layer_norm.bias\n","distilbert.transformer.layer.0.ffn.lin1.weight\n","distilbert.transformer.layer.0.ffn.lin1.bias\n","distilbert.transformer.layer.0.ffn.lin2.weight\n","distilbert.transformer.layer.0.ffn.lin2.bias\n","distilbert.transformer.layer.0.output_layer_norm.weight\n","distilbert.transformer.layer.0.output_layer_norm.bias\n","distilbert.transformer.layer.1.attention.q_lin.weight\n","distilbert.transformer.layer.1.attention.q_lin.bias\n","distilbert.transformer.layer.1.attention.k_lin.weight\n","distilbert.transformer.layer.1.attention.k_lin.bias\n","distilbert.transformer.layer.1.attention.v_lin.weight\n","distilbert.transformer.layer.1.attention.v_lin.bias\n","distilbert.transformer.layer.1.attention.out_lin.weight\n","distilbert.transformer.layer.1.attention.out_lin.bias\n","distilbert.transformer.layer.1.sa_layer_norm.weight\n","distilbert.transformer.layer.1.sa_layer_norm.bias\n","distilbert.transformer.layer.1.ffn.lin1.weight\n","distilbert.transformer.layer.1.ffn.lin1.bias\n","distilbert.transformer.layer.1.ffn.lin2.weight\n","distilbert.transformer.layer.1.ffn.lin2.bias\n","distilbert.transformer.layer.1.output_layer_norm.weight\n","distilbert.transformer.layer.1.output_layer_norm.bias\n","distilbert.transformer.layer.2.attention.q_lin.weight\n","distilbert.transformer.layer.2.attention.q_lin.bias\n","distilbert.transformer.layer.2.attention.k_lin.weight\n","distilbert.transformer.layer.2.attention.k_lin.bias\n","distilbert.transformer.layer.2.attention.v_lin.weight\n","distilbert.transformer.layer.2.attention.v_lin.bias\n","distilbert.transformer.layer.2.attention.out_lin.weight\n","distilbert.transformer.layer.2.attention.out_lin.bias\n","distilbert.transformer.layer.2.sa_layer_norm.weight\n","distilbert.transformer.layer.2.sa_layer_norm.bias\n","distilbert.transformer.layer.2.ffn.lin1.weight\n","distilbert.transformer.layer.2.ffn.lin1.bias\n","distilbert.transformer.layer.2.ffn.lin2.weight\n","distilbert.transformer.layer.2.ffn.lin2.bias\n","distilbert.transformer.layer.2.output_layer_norm.weight\n","distilbert.transformer.layer.2.output_layer_norm.bias\n","distilbert.transformer.layer.3.attention.q_lin.weight\n","distilbert.transformer.layer.3.attention.q_lin.bias\n","distilbert.transformer.layer.3.attention.k_lin.weight\n","distilbert.transformer.layer.3.attention.k_lin.bias\n","distilbert.transformer.layer.3.attention.v_lin.weight\n","distilbert.transformer.layer.3.attention.v_lin.bias\n","distilbert.transformer.layer.3.attention.out_lin.weight\n","distilbert.transformer.layer.3.attention.out_lin.bias\n","distilbert.transformer.layer.3.sa_layer_norm.weight\n","distilbert.transformer.layer.3.sa_layer_norm.bias\n","distilbert.transformer.layer.3.ffn.lin1.weight\n","distilbert.transformer.layer.3.ffn.lin1.bias\n","distilbert.transformer.layer.3.ffn.lin2.weight\n","distilbert.transformer.layer.3.ffn.lin2.bias\n","distilbert.transformer.layer.3.output_layer_norm.weight\n","distilbert.transformer.layer.3.output_layer_norm.bias\n","distilbert.transformer.layer.4.attention.q_lin.weight\n","distilbert.transformer.layer.4.attention.q_lin.bias\n","distilbert.transformer.layer.4.attention.k_lin.weight\n","distilbert.transformer.layer.4.attention.k_lin.bias\n","distilbert.transformer.layer.4.attention.v_lin.weight\n","distilbert.transformer.layer.4.attention.v_lin.bias\n","distilbert.transformer.layer.4.attention.out_lin.weight\n","distilbert.transformer.layer.4.attention.out_lin.bias\n","distilbert.transformer.layer.4.sa_layer_norm.weight\n","distilbert.transformer.layer.4.sa_layer_norm.bias\n","distilbert.transformer.layer.4.ffn.lin1.weight\n","distilbert.transformer.layer.4.ffn.lin1.bias\n","distilbert.transformer.layer.4.ffn.lin2.weight\n","distilbert.transformer.layer.4.ffn.lin2.bias\n","distilbert.transformer.layer.4.output_layer_norm.weight\n","distilbert.transformer.layer.4.output_layer_norm.bias\n","distilbert.transformer.layer.5.attention.q_lin.weight\n","distilbert.transformer.layer.5.attention.q_lin.bias\n","distilbert.transformer.layer.5.attention.k_lin.weight\n","distilbert.transformer.layer.5.attention.k_lin.bias\n","distilbert.transformer.layer.5.attention.v_lin.weight\n","distilbert.transformer.layer.5.attention.v_lin.bias\n","distilbert.transformer.layer.5.attention.out_lin.weight\n","distilbert.transformer.layer.5.attention.out_lin.bias\n","distilbert.transformer.layer.5.sa_layer_norm.weight\n","distilbert.transformer.layer.5.sa_layer_norm.bias\n","distilbert.transformer.layer.5.ffn.lin1.weight\n","distilbert.transformer.layer.5.ffn.lin1.bias\n","distilbert.transformer.layer.5.ffn.lin2.weight\n","distilbert.transformer.layer.5.ffn.lin2.bias\n","distilbert.transformer.layer.5.output_layer_norm.weight\n","distilbert.transformer.layer.5.output_layer_norm.bias\n","pre_classifier.weight\n","pre_classifier.bias\n","classifier.weight\n","classifier.bias\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBbUTmveQIo8"},"outputs":[],"source":["#path=foldername+\"dataset2.csv\"\n","path=foldername+\"balanced_EI_dataset1.csv\"\n","dataset_EI=Ds(path, tokenizer, i=0)\n","\n","#dataset_SN=Ds_SN(path, tokenizer)\n","#dl_SN=getdl(dataset_SN)\n","\n","#dataset_TF=Ds_TF(path, tokenizer)\n","#dl_TF=getdl(dataset_TF)\n","\n","#dataset_JP=Ds_JP(path, tokenizer)\n","#dl_JP=getdl(dataset_JP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KIre8ZH7MQU9"},"outputs":[],"source":["import numpy as np\n","import evaluate\n","\n","metric = evaluate.load(\"accuracy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3WXcTZCMX6-"},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1669863574255,"user":{"displayName":"Qingwan Cheng","userId":"11348850375708644329"},"user_tz":300},"id":"20FUzAxCsugJ","outputId":"ab0dfa41-17ae-4efc-8e56-03b065bfee75"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":44}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","#device = 'cpu'\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dgz4HHvysvAA"},"outputs":[],"source":["class CustomTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.get(\"labels\")\n","        # forward pass\n","        outputs = model(**inputs)\n","        logits = outputs.get(\"logits\")\n","        # compute custom loss (suppose one has 3 labels with different weights)\n","        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 3.2726])).to(device)\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1)).to(device)\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qgbkR3f6OaRN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669863574256,"user_tz":300,"elapsed":13,"user":{"displayName":"Qingwan Cheng","userId":"11348850375708644329"}},"outputId":"d0132d55-d4fc-480a-857f-71facbea4d9e"},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["from transformers import TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(output_dir=foldername+\"test_trainer\", \n","                                  evaluation_strategy=\"epoch\", \n","                                  num_train_epochs=30, \n","                                  per_device_train_batch_size=32, \n","                                  per_device_eval_batch_size=32,\n","                                  save_steps=1e5,\n","                                  weight_decay=0.01,\n","                                  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUnxLaDkPBCs"},"outputs":[],"source":["total_len=len(dataset_EI)\n","train_len=int(len(dataset_EI)*0.9)\n","val_len=int(total_len-train_len)\n","[train_ds, val_ds]=torch.utils.data.random_split(dataset_EI, [train_len, val_len])\n","data_collator=DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"caCTxQidMm2j"},"outputs":[],"source":["trainer = CustomTrainer(\n","    #model=bertmodel,\n","    model=distilbertmodel,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_ds,\n","    eval_dataset=val_ds,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"viIpzl2tOmUE","outputId":"e23a466a-1f9d-4d75-df3c-e6f47fa47fbf","executionInfo":{"status":"ok","timestamp":1669875239089,"user_tz":300,"elapsed":5341206,"user":{"displayName":"Qingwan Cheng","userId":"11348850375708644329"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 166779\n","  Num Epochs = 30\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 156360\n","  Number of trainable parameters = 592130\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='84660' max='156360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 84660/156360 1:45:22 < 1:29:15, 13.39 it/s, Epoch 16.24/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.544500</td>\n","      <td>0.542906</td>\n","      <td>0.498624</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.539900</td>\n","      <td>0.542737</td>\n","      <td>0.498624</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.541200</td>\n","      <td>0.542591</td>\n","      <td>0.498786</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.537100</td>\n","      <td>0.544046</td>\n","      <td>0.501106</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.538500</td>\n","      <td>0.541049</td>\n","      <td>0.498678</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.542000</td>\n","      <td>0.542226</td>\n","      <td>0.499811</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.543500</td>\n","      <td>0.541871</td>\n","      <td>0.498948</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.538700</td>\n","      <td>0.540731</td>\n","      <td>0.499110</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.535900</td>\n","      <td>0.540689</td>\n","      <td>0.500027</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.530300</td>\n","      <td>0.540154</td>\n","      <td>0.500189</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.540400</td>\n","      <td>0.539633</td>\n","      <td>0.499757</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.532800</td>\n","      <td>0.540011</td>\n","      <td>0.500081</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.534000</td>\n","      <td>0.539745</td>\n","      <td>0.500081</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.538800</td>\n","      <td>0.539771</td>\n","      <td>0.500513</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.535600</td>\n","      <td>0.539419</td>\n","      <td>0.500513</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.539400</td>\n","      <td>0.540254</td>\n","      <td>0.499433</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='156360' max='156360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [156360/156360 3:14:24, Epoch 30/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.544500</td>\n","      <td>0.542906</td>\n","      <td>0.498624</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.539900</td>\n","      <td>0.542737</td>\n","      <td>0.498624</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.541200</td>\n","      <td>0.542591</td>\n","      <td>0.498786</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.537100</td>\n","      <td>0.544046</td>\n","      <td>0.501106</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.538500</td>\n","      <td>0.541049</td>\n","      <td>0.498678</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.542000</td>\n","      <td>0.542226</td>\n","      <td>0.499811</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.543500</td>\n","      <td>0.541871</td>\n","      <td>0.498948</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.538700</td>\n","      <td>0.540731</td>\n","      <td>0.499110</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.535900</td>\n","      <td>0.540689</td>\n","      <td>0.500027</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.530300</td>\n","      <td>0.540154</td>\n","      <td>0.500189</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.540400</td>\n","      <td>0.539633</td>\n","      <td>0.499757</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.532800</td>\n","      <td>0.540011</td>\n","      <td>0.500081</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.534000</td>\n","      <td>0.539745</td>\n","      <td>0.500081</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.538800</td>\n","      <td>0.539771</td>\n","      <td>0.500513</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.535600</td>\n","      <td>0.539419</td>\n","      <td>0.500513</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.539400</td>\n","      <td>0.540254</td>\n","      <td>0.499433</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.531800</td>\n","      <td>0.539655</td>\n","      <td>0.500675</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.539700</td>\n","      <td>0.539182</td>\n","      <td>0.499757</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.527300</td>\n","      <td>0.538979</td>\n","      <td>0.499811</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.530500</td>\n","      <td>0.538626</td>\n","      <td>0.500513</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.535600</td>\n","      <td>0.539177</td>\n","      <td>0.501646</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.529400</td>\n","      <td>0.538505</td>\n","      <td>0.500998</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.529700</td>\n","      <td>0.538409</td>\n","      <td>0.500998</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.527700</td>\n","      <td>0.538365</td>\n","      <td>0.501376</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.529600</td>\n","      <td>0.538460</td>\n","      <td>0.500836</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.532500</td>\n","      <td>0.538248</td>\n","      <td>0.501052</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.534700</td>\n","      <td>0.538187</td>\n","      <td>0.501808</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.534800</td>\n","      <td>0.538278</td>\n","      <td>0.501214</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.532800</td>\n","      <td>0.538190</td>\n","      <td>0.501214</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.533200</td>\n","      <td>0.538192</td>\n","      <td>0.501322</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","Saving model checkpoint to /content/drive/My Drive/Project/extractedfeaturewithbert/test_trainer/checkpoint-100000\n","Configuration saved in /content/drive/My Drive/Project/extractedfeaturewithbert/test_trainer/checkpoint-100000/config.json\n","Model weights saved in /content/drive/My Drive/Project/extractedfeaturewithbert/test_trainer/checkpoint-100000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 18531\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=156360, training_loss=0.535703285492482, metrics={'train_runtime': 11664.1435, 'train_samples_per_second': 428.953, 'train_steps_per_second': 13.405, 'total_flos': 6.4724942227878e+16, 'train_loss': 0.535703285492482, 'epoch': 30.0})"]},"metadata":{},"execution_count":49}],"source":["trainer.train()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}