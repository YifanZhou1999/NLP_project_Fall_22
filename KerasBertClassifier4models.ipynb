{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkOK2tyUSrMQ"
   },
   "source": [
    "## Install Dependencies and Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lJLc9wVXSq3R"
   },
   "outputs": [],
   "source": [
    "#!python3 -m pip install transformers\n",
    "#!python3 -m pip install sentencepiece\n",
    "#!git clone https://github.com/YifanZhou1999/NLP_Project_datasets_fall22.git\n",
    "!mkdir data\n",
    "!mkdir models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8tIN7QsTt1D"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1669828344427,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "HYj1dGqtRhzl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import itertools\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_stopwords_shortwords(w):\n",
    "    stopwords_list=stopwords.words('english')\n",
    "    words = w.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
    "    return \" \".join(clean_words) \n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w=clean_stopwords_shortwords(w)\n",
    "    w=re.sub(r'@\\w+', '',w)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHfP5x5IUhUA"
   },
   "source": [
    "## Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "executionInfo": {
     "elapsed": 1051,
     "status": "ok",
     "timestamp": 1669828915741,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "rVKiG3ZATpav",
    "outputId": "f3b1e8f5-6869-4a81-ccd2-38962aa19e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has 185310 rows and 2 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>May the PerC Experience immerse you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Hello ENFJ7. Sorry to hear of your distress. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Welcome and stuff.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Prozac, wellbrutin, at least thirty minutes of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               post\n",
       "0  INFJ  What has been the most life-changing experienc...\n",
       "1  INFJ               May the PerC Experience immerse you.\n",
       "2  INFJ  Hello ENFJ7. Sorry to hear of your distress. I...\n",
       "3  INFJ                                 Welcome and stuff.\n",
       "4  INFJ  Prozac, wellbrutin, at least thirty minutes of..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_file=\"/content/NLP_Project_datasets_fall22/dataset2.csv\"\n",
    "#data_file=\"./dataset2.csv\"\n",
    "data_file=\"balanced_EI_dataset.csv\"\n",
    "dataf = pd.read_csv(data_file).dropna()\n",
    "print('File has {} rows and {} columns'.format(dataf.shape[0],dataf.shape[1]))\n",
    "dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "executionInfo": {
     "elapsed": 933,
     "status": "ok",
     "timestamp": 1669828929638,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "-Y9mxg0qVbn5",
    "outputId": "e8624958-6acd-407a-fa62-e2219d09c669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185310 185310\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>post</th>\n",
       "      <th>EI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>May the PerC Experience immerse you.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Hello ENFJ7. Sorry to hear of your distress. I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Welcome and stuff.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Prozac, wellbrutin, at least thirty minutes of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               post  EI\n",
       "0  INFJ  What has been the most life-changing experienc...   0\n",
       "1  INFJ               May the PerC Experience immerse you.   0\n",
       "2  INFJ  Hello ENFJ7. Sorry to hear of your distress. I...   0\n",
       "3  INFJ                                 Welcome and stuff.   0\n",
       "4  INFJ  Prozac, wellbrutin, at least thirty minutes of...   0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def labelconv(x):\n",
    "    return 1 if x[0] == 'E' else 0\n",
    "\n",
    "dataf['EI'] = dataf['type'].map(lambda x:labelconv(x))\n",
    "print(len(dataf['post']), len(dataf['EI']))\n",
    "dataf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1flrVaRcUcaB"
   },
   "source": [
    "## Setting up pretrained BERT Model and Tokenizer\n",
    "\n",
    "- Use distilbert-base-uncased\n",
    "- numclass = 2\n",
    "\n",
    "*   列表项\n",
    "*   列表项\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3549,
     "status": "ok",
     "timestamp": 1669828937504,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "g7g-1vDEUma3",
    "outputId": "ab2dc90d-c1b4-47e5-d932-55545a7272cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file tf_model.h5 from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tf_model.h5\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'dropout_39', 'pre_classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import *\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel, BertConfig\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "bert_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "bert_model_EI = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7pJ7ZUXYR0O"
   },
   "source": [
    "## Tokenize\n",
    "\n",
    "~ 10 minues to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 652058,
     "status": "ok",
     "timestamp": 1669829647016,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "L41HVHgtYT1P",
    "outputId": "e3a2698d-263b-4888-bc9f-909542d4328e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:\n",
      "0\r",
      "1\r",
      "2\r",
      "3\r",
      "4\r",
      "5\r",
      "6\r",
      "7\r",
      "8\r",
      "9\r",
      "10\r",
      "11\r",
      "12\r",
      "13\r",
      "14\r",
      "15\r",
      "16\r",
      "17\r",
      "18\r",
      "19\r",
      "20\r",
      "21\r",
      "22\r",
      "23\r",
      "24\r",
      "25\r",
      "26\r",
      "27\r",
      "28\r",
      "29\r",
      "30\r",
      "31\r",
      "32\r",
      "33\r",
      "34\r",
      "35\r",
      "36\r",
      "37\r",
      "38\r",
      "39\r",
      "40\r",
      "41\r",
      "42\r",
      "43\r",
      "44\r",
      "45\r",
      "46\r",
      "47\r",
      "48\r",
      "49\r",
      "50\r",
      "51\r",
      "52\r",
      "53\r",
      "54\r",
      "55\r",
      "56\r",
      "57\r",
      "58\r",
      "59\r",
      "60\r",
      "61\r",
      "62\r",
      "63\r",
      "64\r",
      "65\r",
      "66\r",
      "67\r",
      "68\r",
      "69\r",
      "70\r",
      "71\r",
      "72\r",
      "73\r",
      "74\r",
      "75\r",
      "76\r",
      "77\r",
      "78\r",
      "79\r",
      "80\r",
      "81\r",
      "82\r",
      "83\r",
      "84\r",
      "85\r",
      "86\r",
      "87\r",
      "88\r",
      "89\r",
      "90\r",
      "91\r",
      "92\r",
      "93\r",
      "94\r",
      "95\r",
      "96\r",
      "97\r",
      "98\r",
      "99\r",
      "100\r",
      "101\r",
      "102\r",
      "103\r",
      "104\r",
      "105\r",
      "106\r",
      "107\r",
      "108\r",
      "109\r",
      "110\r",
      "111\r",
      "112\r",
      "113\r",
      "114\r",
      "115\r",
      "116\r",
      "117\r",
      "118\r",
      "119\r",
      "120\r",
      "121\r",
      "122\r",
      "123\r",
      "124\r",
      "125\r",
      "126\r",
      "127\r",
      "128\r",
      "129\r",
      "130\r",
      "131\r",
      "132\r",
      "133\r",
      "134\r",
      "135\r",
      "136\r",
      "137\r",
      "138\r",
      "139\r",
      "140\r",
      "141\r",
      "142\r",
      "143\r",
      "144\r",
      "145\r",
      "146\r",
      "147\r",
      "148\r",
      "149\r",
      "150\r",
      "151\r",
      "152\r",
      "153\r",
      "154\r",
      "155\r",
      "156\r",
      "157\r",
      "158\r",
      "159\r",
      "160\r",
      "161\r",
      "162\r",
      "163\r",
      "164\r",
      "165\r",
      "166\r",
      "167\r",
      "168\r",
      "169\r",
      "170\r",
      "171\r",
      "172\r",
      "173\r",
      "174\r",
      "175\r",
      "176\r",
      "177\r",
      "178\r",
      "179\r",
      "180\r",
      "181\r",
      "182\r",
      "183\r",
      "184\r",
      "185\r",
      "186\r",
      "187\r",
      "188\r",
      "189\r",
      "190\r",
      "191\r",
      "192\r",
      "193\r",
      "194\r",
      "195\r",
      "196\r",
      "197\r",
      "198\r",
      "199\r",
      "200\r",
      "201\r",
      "202\r",
      "203\r",
      "204\r",
      "205\r",
      "206\r",
      "207\r",
      "208\r",
      "209\r",
      "210\r",
      "211\r",
      "212\r",
      "213\r",
      "214\r",
      "215\r",
      "216\r",
      "217\r",
      "218\r",
      "219\r",
      "220\r",
      "221\r",
      "222\r",
      "223\r",
      "224\r",
      "225\r",
      "226\r",
      "227\r",
      "228\r",
      "229\r",
      "230\r",
      "231\r",
      "232\r",
      "233\r",
      "234\r",
      "235\r",
      "236\r",
      "237\r",
      "238\r",
      "239\r",
      "240\r",
      "241\r",
      "242\r",
      "243\r",
      "244\r",
      "245\r",
      "246\r",
      "247\r",
      "248\r",
      "249\r",
      "250\r",
      "251\r",
      "252\r",
      "253\r",
      "254\r",
      "255\r",
      "256\r",
      "257\r",
      "258\r",
      "259\r",
      "260\r",
      "261\r",
      "262\r",
      "263\r",
      "264\r",
      "265\r",
      "266\r",
      "267\r",
      "268\r",
      "269\r",
      "270\r",
      "271\r",
      "272\r",
      "273\r",
      "274\r",
      "275\r",
      "276\r",
      "277\r",
      "278\r",
      "279\r",
      "280\r",
      "281\r",
      "282\r",
      "283\r",
      "284\r",
      "285\r",
      "286\r",
      "287\r",
      "288\r",
      "289\r",
      "290\r",
      "291\r",
      "292\r",
      "293\r",
      "294\r",
      "295\r",
      "296\r",
      "297\r",
      "298\r",
      "299\r",
      "300\r",
      "301\r",
      "302\r",
      "303\r",
      "304\r",
      "305\r",
      "306\r",
      "307\r",
      "308\r",
      "309\r",
      "310\r",
      "311\r",
      "312\r",
      "313\r",
      "314\r",
      "315\r",
      "316\r",
      "317\r",
      "318\r",
      "319\r",
      "320\r",
      "321\r",
      "322\r",
      "323\r",
      "324\r",
      "325\r",
      "326\r",
      "327\r",
      "328\r",
      "329\r",
      "330\r",
      "331\r",
      "332\r",
      "333\r",
      "334\r",
      "335\r",
      "336\r",
      "337\r",
      "338\r",
      "339\r",
      "340\r",
      "341\r",
      "342\r",
      "343\r",
      "344\r",
      "345\r",
      "346\r",
      "347\r",
      "348\r",
      "349\r",
      "350\r",
      "351\r",
      "352\r",
      "353\r",
      "354\r",
      "355\r",
      "356\r",
      "357\r",
      "358\r",
      "359\r",
      "360\r",
      "361\r",
      "362\r",
      "363\r",
      "364\r",
      "365\r",
      "366\r",
      "367\r",
      "368\r",
      "369\r",
      "370\r",
      "371\r",
      "372\r",
      "373\r",
      "374\r",
      "375\r",
      "376\r",
      "377\r",
      "378\r",
      "379\r",
      "380\r",
      "381\r",
      "382\r",
      "383\r",
      "384\r",
      "385\r",
      "386\r",
      "387\r",
      "388\r",
      "389\r",
      "390\r",
      "391\r",
      "392\r",
      "393\r",
      "394\r",
      "395\r",
      "396\r",
      "397\r",
      "398\r",
      "399\r",
      "400\r",
      "401\r",
      "402\r",
      "403\r",
      "404\r",
      "405\r",
      "406\r",
      "407\r",
      "408\r",
      "409\r",
      "410\r",
      "411\r",
      "412\r",
      "413\r",
      "414\r",
      "415\r",
      "416\r",
      "417\r",
      "418\r",
      "419\r",
      "420\r",
      "421\r",
      "422\r",
      "423\r",
      "424\r",
      "425\r",
      "426\r",
      "427\r",
      "428\r",
      "429\r",
      "430\r",
      "431\r",
      "432\r",
      "433\r",
      "434\r",
      "435\r",
      "436\r",
      "437\r",
      "438\r",
      "439\r",
      "440\r",
      "441\r",
      "442\r",
      "443\r",
      "444\r",
      "445\r",
      "446\r",
      "447\r",
      "448\r",
      "449\r",
      "450\r",
      "451\r",
      "452\r",
      "453\r",
      "454\r",
      "455\r",
      "456\r",
      "457\r",
      "458\r",
      "459\r",
      "460\r",
      "461\r",
      "462\r",
      "463\r",
      "464\r",
      "465\r",
      "466\r",
      "467\r",
      "468\r",
      "469\r",
      "470\r",
      "471\r",
      "472\r",
      "473\r",
      "474\r",
      "475\r",
      "476\r",
      "477\r",
      "478\r",
      "479\r",
      "480\r",
      "481\r",
      "482\r",
      "483\r",
      "484\r",
      "485\r",
      "486\r",
      "487\r",
      "488\r",
      "489\r",
      "490\r",
      "491\r",
      "492\r",
      "493\r",
      "494\r",
      "495\r",
      "496\r",
      "497\r",
      "498\r",
      "499\r",
      "500\r",
      "501\r",
      "502\r",
      "503\r",
      "504\r",
      "505\r",
      "506\r",
      "507\r",
      "508\r",
      "509\r",
      "510\r",
      "511\r",
      "512\r",
      "513\r",
      "514\r",
      "515\r",
      "516\r",
      "517\r",
      "518\r",
      "519\r",
      "520\r",
      "521\r",
      "522\r",
      "523\r",
      "524\r",
      "525\r",
      "526\r",
      "527\r",
      "528\r",
      "529\r",
      "530\r",
      "531\r",
      "532\r",
      "533\r",
      "534\r",
      "535\r",
      "536\r",
      "537\r",
      "538\r",
      "539\r",
      "540\r",
      "541\r",
      "542\r",
      "543\r",
      "544\r",
      "545\r",
      "546\r",
      "547\r",
      "548\r",
      "549\r",
      "550\r",
      "551\r",
      "552\r",
      "553\r",
      "554\r",
      "555\r",
      "556\r",
      "557\r",
      "558\r",
      "559\r",
      "560\r",
      "561\r",
      "562\r",
      "563\r",
      "564\r",
      "565\r",
      "566\r",
      "567\r",
      "568\r",
      "569\r",
      "570\r",
      "571\r",
      "572\r",
      "573\r",
      "574\r",
      "575\r",
      "576\r",
      "577\r",
      "578\r",
      "579\r",
      "580\r",
      "581\r",
      "582\r",
      "583\r",
      "584\r",
      "585\r",
      "586\r",
      "587\r",
      "588\r",
      "589\r",
      "590\r",
      "591\r",
      "592\r",
      "593\r",
      "594\r",
      "595\r",
      "596\r",
      "597\r",
      "598\r",
      "599\r",
      "600\r",
      "601\r",
      "602\r",
      "603\r",
      "604\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouyifan/.pyenv/versions/3.9.13/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185309\r"
     ]
    }
   ],
   "source": [
    "input_ids=[]\n",
    "attention_masks=[]\n",
    "\n",
    "sentences = dataf['post']\n",
    "print(\"Progress:\")\n",
    "for id, sent in enumerate(sentences):\n",
    "    print(id, end=\"\\r\")\n",
    "    bert_inp=bert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =64,pad_to_max_length = True,return_attention_mask = True)\n",
    "    input_ids.append(bert_inp['input_ids'])\n",
    "    attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "labels=np.array(dataf['EI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1669829655598,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "ywuCuf1Wks6S",
    "outputId": "309e67e1-8d6c-405d-8d85-d1fa92f70653"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185310, 185310, 185310)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids),len(attention_masks),len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82tmFtmpX-1M"
   },
   "source": [
    "## Saving and Loading Data into the pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1496,
     "status": "ok",
     "timestamp": 1669829686889,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "7JhOjHzJX-hA",
    "outputId": "5b5ae565-f794-44f8-a9cd-efae98f9c3a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the pickle file.....\n",
      "Pickle files saved as  ./data/bert_inp.pkl ./data/bert_mask.pkl ./data/bert_label.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Preparing the pickle file.....')\n",
    "\n",
    "pickle_inp_path='./data/bert_inp.pkl'\n",
    "pickle_mask_path='./data/bert_mask.pkl'\n",
    "pickle_label_path='./data/bert_label.pkl'\n",
    "\n",
    "pickle.dump((input_ids),open(pickle_inp_path,'wb'))\n",
    "pickle.dump((attention_masks),open(pickle_mask_path,'wb'))\n",
    "pickle.dump((labels),open(pickle_label_path,'wb'))\n",
    "\n",
    "\n",
    "print('Pickle files saved as ',pickle_inp_path,pickle_mask_path,pickle_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1669829701137,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "4YK3NHaLYC7v",
    "outputId": "f4ff6cc5-fb74-4b2f-8120-e818ebfc8660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved pickle files..\n",
      "Input shape (185310, 64) Attention mask shape (185310, 64) Input label shape (185310,)\n"
     ]
    }
   ],
   "source": [
    "print('Loading the saved pickle files..')\n",
    "\n",
    "input_ids=pickle.load(open(pickle_inp_path, 'rb'))\n",
    "attention_masks=pickle.load(open(pickle_mask_path, 'rb'))\n",
    "labels=pickle.load(open(pickle_label_path, 'rb'))\n",
    "\n",
    "print('Input shape {} Attention mask shape {} Input label shape {}'.format(input_ids.shape,attention_masks.shape,labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VC25uoYmBFV"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1669829707842,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "XbwAcXrvmChl",
    "outputId": "c0869858-3449-4f61-f56c-159634c37591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inp shape (148248, 64) Val input shape (37062, 64)\n",
      "Train label shape (148248,) Val label shape (37062,)\n",
      "Train attention mask shape (148248, 64) Val attention mask shape (37062, 64)\n"
     ]
    }
   ],
   "source": [
    "train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.2)\n",
    "\n",
    "print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jdo-wzmem3fS"
   },
   "source": [
    "## Training Setup\n",
    "- Loss\n",
    "- Optimizer\n",
    "- Other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 721,
     "status": "ok",
     "timestamp": 1669829807097,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "ylg7TmAim2-u",
    "outputId": "7e5ea407-6b02-4430-ba3e-c12ceed1e179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMai  multiple                 66362880  \n",
      " nLayer)                                                         \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,955,010\n",
      "Trainable params: 66,955,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Bert Model None\n"
     ]
    }
   ],
   "source": [
    "log_dir='tensorboard_data/tb_bert'\n",
    "model_save_path='./models/bert_model.h5'\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "print('\\nBert Model',bert_model_EI.summary())\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08)\n",
    "\n",
    "bert_model_EI.compile(loss=loss,optimizer=optimizer,metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGd3k24vnXuc"
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1669830752665,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "ee3T4Hjio_gL",
    "outputId": "21d5d438-6b7b-4835-c21d-3296e9179f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16187636843698942967\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 18244839580041451167\n",
      "physical_device_desc: \"device: 0, name: METAL, pci bus id: <undefined>\"\n",
      "xla_global_id: -1\n",
      "]\n",
      "\n",
      "\n",
      "\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 14:12:07.723580: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-30 14:12:07.723624: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-11-30 14:12:07.725059: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-30 14:12:07.725087: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Check Device\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(\"\\n\\n\")\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "executionInfo": {
     "elapsed": 282503,
     "status": "error",
     "timestamp": 1669830269296,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "FjsZ6kianZo4",
    "outputId": "0741897b-f03b-4f94-9d28-8b3de3f928c9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 16:57:12.151307: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4633/4633 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.5885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 17:10:54.753757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4633/4633 [==============================] - 914s 195ms/step - loss: 0.6603 - accuracy: 0.5885 - val_loss: 0.6472 - val_accuracy: 0.6090\n",
      "Epoch 2/50\n",
      "4633/4633 [==============================] - 888s 192ms/step - loss: 0.6250 - accuracy: 0.6377 - val_loss: 0.6511 - val_accuracy: 0.6025\n",
      "Epoch 3/50\n",
      "4633/4633 [==============================] - 881s 190ms/step - loss: 0.5582 - accuracy: 0.7024 - val_loss: 0.6796 - val_accuracy: 0.6078\n",
      "Epoch 4/50\n",
      "4633/4633 [==============================] - 879s 190ms/step - loss: 0.4534 - accuracy: 0.7789 - val_loss: 0.7787 - val_accuracy: 0.5985\n",
      "Epoch 5/50\n",
      "4633/4633 [==============================] - 879s 190ms/step - loss: 0.3483 - accuracy: 0.8397 - val_loss: 0.8950 - val_accuracy: 0.5985\n",
      "Epoch 6/50\n",
      "4633/4633 [==============================] - 880s 190ms/step - loss: 0.2641 - accuracy: 0.8840 - val_loss: 1.0708 - val_accuracy: 0.5928\n",
      "Epoch 7/50\n",
      "4633/4633 [==============================] - 884s 191ms/step - loss: 0.2036 - accuracy: 0.9137 - val_loss: 1.2241 - val_accuracy: 0.5917\n",
      "Epoch 8/50\n",
      "4633/4633 [==============================] - 881s 190ms/step - loss: 0.1581 - accuracy: 0.9347 - val_loss: 1.4834 - val_accuracy: 0.5928\n",
      "Epoch 9/50\n",
      "4633/4633 [==============================] - 876s 189ms/step - loss: 0.1302 - accuracy: 0.9472 - val_loss: 1.4884 - val_accuracy: 0.5906\n",
      "Epoch 10/50\n",
      "4633/4633 [==============================] - 878s 190ms/step - loss: 0.1113 - accuracy: 0.9559 - val_loss: 1.5241 - val_accuracy: 0.5881\n",
      "Epoch 11/50\n",
      "4633/4633 [==============================] - 879s 190ms/step - loss: 0.0930 - accuracy: 0.9631 - val_loss: 1.7689 - val_accuracy: 0.5902\n",
      "Epoch 12/50\n",
      "4633/4633 [==============================] - 880s 190ms/step - loss: 0.0827 - accuracy: 0.9681 - val_loss: 1.8432 - val_accuracy: 0.5841\n",
      "Epoch 13/50\n",
      "4633/4633 [==============================] - 881s 190ms/step - loss: 0.0732 - accuracy: 0.9712 - val_loss: 1.8705 - val_accuracy: 0.5952\n",
      "Epoch 14/50\n",
      "4633/4633 [==============================] - 882s 190ms/step - loss: 0.0662 - accuracy: 0.9740 - val_loss: 1.9269 - val_accuracy: 0.5910\n",
      "Epoch 15/50\n",
      "4633/4633 [==============================] - 882s 190ms/step - loss: 0.0600 - accuracy: 0.9771 - val_loss: 1.8981 - val_accuracy: 0.5936\n",
      "Epoch 16/50\n",
      "4633/4633 [==============================] - 884s 191ms/step - loss: 0.0550 - accuracy: 0.9790 - val_loss: 1.9770 - val_accuracy: 0.5886\n",
      "Epoch 17/50\n",
      " 944/4633 [=====>........................] - ETA: 10:37 - loss: 0.0480 - accuracy: 0.9824"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mbert_model_EI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/keras/engine/training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/keras/callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/keras/callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/keras/callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/keras/callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/keras/callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/keras/callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/keras/utils/tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/keras/utils/tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=bert_model_EI.fit([train_inp,train_mask],train_label,batch_size=32,epochs=50,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RD3Hyq7Any1G"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrFbkCtdn0TA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMncS9Y9ykuufO84+892jEb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
