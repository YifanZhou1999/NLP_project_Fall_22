{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkOK2tyUSrMQ"
   },
   "source": [
    "## Install Dependencies and Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lJLc9wVXSq3R"
   },
   "outputs": [],
   "source": [
    "#!python3 -m pip install transformers\n",
    "#!python3 -m pip install sentencepiece\n",
    "#!git clone https://github.com/YifanZhou1999/NLP_Project_datasets_fall22.git\n",
    "!mkdir data\n",
    "!mkdir models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8tIN7QsTt1D"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1669828344427,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "HYj1dGqtRhzl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import itertools\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_stopwords_shortwords(w):\n",
    "    stopwords_list=stopwords.words('english')\n",
    "    words = w.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
    "    return \" \".join(clean_words) \n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w=clean_stopwords_shortwords(w)\n",
    "    w=re.sub(r'@\\w+', '',w)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHfP5x5IUhUA"
   },
   "source": [
    "## Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "executionInfo": {
     "elapsed": 1051,
     "status": "ok",
     "timestamp": 1669828915741,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "rVKiG3ZATpav",
    "outputId": "f3b1e8f5-6869-4a81-ccd2-38962aa19e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has 185310 rows and 2 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>May the PerC Experience immerse you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Hello ENFJ7. Sorry to hear of your distress. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Welcome and stuff.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Prozac, wellbrutin, at least thirty minutes of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               post\n",
       "0  INFJ  What has been the most life-changing experienc...\n",
       "1  INFJ               May the PerC Experience immerse you.\n",
       "2  INFJ  Hello ENFJ7. Sorry to hear of your distress. I...\n",
       "3  INFJ                                 Welcome and stuff.\n",
       "4  INFJ  Prozac, wellbrutin, at least thirty minutes of..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_file=\"/content/NLP_Project_datasets_fall22/dataset2.csv\"\n",
    "#data_file=\"./dataset2.csv\"\n",
    "data_file=\"balanced_EI_dataset.csv\"\n",
    "dataf = pd.read_csv(data_file).dropna()\n",
    "print('File has {} rows and {} columns'.format(dataf.shape[0],dataf.shape[1]))\n",
    "dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "executionInfo": {
     "elapsed": 933,
     "status": "ok",
     "timestamp": 1669828929638,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "-Y9mxg0qVbn5",
    "outputId": "e8624958-6acd-407a-fa62-e2219d09c669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185310 185310\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>post</th>\n",
       "      <th>EI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>May the PerC Experience immerse you.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Hello ENFJ7. Sorry to hear of your distress. I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Welcome and stuff.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>Prozac, wellbrutin, at least thirty minutes of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               post  EI\n",
       "0  INFJ  What has been the most life-changing experienc...   0\n",
       "1  INFJ               May the PerC Experience immerse you.   0\n",
       "2  INFJ  Hello ENFJ7. Sorry to hear of your distress. I...   0\n",
       "3  INFJ                                 Welcome and stuff.   0\n",
       "4  INFJ  Prozac, wellbrutin, at least thirty minutes of...   0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def labelconv(x):\n",
    "    return 1 if x[0] == 'E' else 0\n",
    "\n",
    "dataf['EI'] = dataf['type'].map(lambda x:labelconv(x))\n",
    "print(len(dataf['post']), len(dataf['EI']))\n",
    "dataf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1flrVaRcUcaB"
   },
   "source": [
    "## Setting up pretrained BERT Model and Tokenizer\n",
    "\n",
    "- Use distilbert-base-uncased\n",
    "- numclass = 2\n",
    "\n",
    "*   列表项\n",
    "*   列表项\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3549,
     "status": "ok",
     "timestamp": 1669828937504,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "g7g-1vDEUma3",
    "outputId": "ab2dc90d-c1b4-47e5-d932-55545a7272cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file tf_model.h5 from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tf_model.h5\n",
      "2022-11-30 21:20:38.151591: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-30 21:20:38.151741: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import *\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel, BertConfig\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "bert_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "bert_model_EI = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7pJ7ZUXYR0O"
   },
   "source": [
    "## Tokenize\n",
    "\n",
    "~ 10 minues to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 652058,
     "status": "ok",
     "timestamp": 1669829647016,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "L41HVHgtYT1P",
    "outputId": "e3a2698d-263b-4888-bc9f-909542d4328e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:\n",
      "0\r",
      "1\r",
      "2\r",
      "3\r",
      "4\r",
      "5\r",
      "6\r",
      "7\r",
      "8\r",
      "9\r",
      "10\r",
      "11\r",
      "12\r",
      "13\r",
      "14\r",
      "15\r",
      "16\r",
      "17\r",
      "18\r",
      "19\r",
      "20\r",
      "21\r",
      "22\r",
      "23\r",
      "24\r",
      "25\r",
      "26\r",
      "27\r",
      "28\r",
      "29\r",
      "30\r",
      "31\r",
      "32\r",
      "33\r",
      "34\r",
      "35\r",
      "36\r",
      "37\r",
      "38\r",
      "39\r",
      "40\r",
      "41\r",
      "42\r",
      "43\r",
      "44\r",
      "45\r",
      "46\r",
      "47\r",
      "48\r",
      "49\r",
      "50\r",
      "51\r",
      "52\r",
      "53\r",
      "54\r",
      "55\r",
      "56\r",
      "57\r",
      "58\r",
      "59\r",
      "60\r",
      "61\r",
      "62\r",
      "63\r",
      "64\r",
      "65\r",
      "66\r",
      "67\r",
      "68\r",
      "69\r",
      "70\r",
      "71\r",
      "72\r",
      "73\r",
      "74\r",
      "75\r",
      "76\r",
      "77\r",
      "78\r",
      "79\r",
      "80\r",
      "81\r",
      "82\r",
      "83\r",
      "84\r",
      "85\r",
      "86\r",
      "87\r",
      "88\r",
      "89\r",
      "90\r",
      "91\r",
      "92\r",
      "93\r",
      "94\r",
      "95\r",
      "96\r",
      "97\r",
      "98\r",
      "99\r",
      "100\r",
      "101\r",
      "102\r",
      "103\r",
      "104\r",
      "105\r",
      "106\r",
      "107\r",
      "108\r",
      "109\r",
      "110\r",
      "111\r",
      "112\r",
      "113\r",
      "114\r",
      "115\r",
      "116\r",
      "117\r",
      "118\r",
      "119\r",
      "120\r",
      "121\r",
      "122\r",
      "123\r",
      "124\r",
      "125\r",
      "126\r",
      "127\r",
      "128\r",
      "129\r",
      "130\r",
      "131\r",
      "132\r",
      "133\r",
      "134\r",
      "135\r",
      "136\r",
      "137\r",
      "138\r",
      "139\r",
      "140\r",
      "141\r",
      "142\r",
      "143\r",
      "144\r",
      "145\r",
      "146\r",
      "147\r",
      "148\r",
      "149\r",
      "150\r",
      "151\r",
      "152\r",
      "153\r",
      "154\r",
      "155\r",
      "156\r",
      "157\r",
      "158\r",
      "159\r",
      "160\r",
      "161\r",
      "162\r",
      "163\r",
      "164\r",
      "165\r",
      "166\r",
      "167\r",
      "168\r",
      "169\r",
      "170\r",
      "171\r",
      "172\r",
      "173\r",
      "174\r",
      "175\r",
      "176\r",
      "177\r",
      "178\r",
      "179\r",
      "180\r",
      "181\r",
      "182\r",
      "183\r",
      "184\r",
      "185\r",
      "186\r",
      "187\r",
      "188\r",
      "189\r",
      "190\r",
      "191\r",
      "192\r",
      "193\r",
      "194\r",
      "195\r",
      "196\r",
      "197\r",
      "198\r",
      "199\r",
      "200\r",
      "201\r",
      "202\r",
      "203\r",
      "204\r",
      "205\r",
      "206\r",
      "207\r",
      "208\r",
      "209\r",
      "210\r",
      "211\r",
      "212\r",
      "213\r",
      "214\r",
      "215\r",
      "216\r",
      "217\r",
      "218\r",
      "219\r",
      "220\r",
      "221\r",
      "222\r",
      "223\r",
      "224\r",
      "225\r",
      "226\r",
      "227\r",
      "228\r",
      "229\r",
      "230\r",
      "231\r",
      "232\r",
      "233\r",
      "234\r",
      "235\r",
      "236\r",
      "237\r",
      "238\r",
      "239\r",
      "240\r",
      "241\r",
      "242\r",
      "243\r",
      "244\r",
      "245\r",
      "246\r",
      "247\r",
      "248\r",
      "249\r",
      "250\r",
      "251\r",
      "252\r",
      "253\r",
      "254\r",
      "255\r",
      "256\r",
      "257\r",
      "258\r",
      "259\r",
      "260\r",
      "261\r",
      "262\r",
      "263\r",
      "264\r",
      "265\r",
      "266\r",
      "267\r",
      "268\r",
      "269\r",
      "270\r",
      "271\r",
      "272\r",
      "273\r",
      "274\r",
      "275\r",
      "276\r",
      "277\r",
      "278\r",
      "279\r",
      "280\r",
      "281\r",
      "282\r",
      "283\r",
      "284\r",
      "285\r",
      "286\r",
      "287\r",
      "288\r",
      "289\r",
      "290\r",
      "291\r",
      "292\r",
      "293\r",
      "294\r",
      "295\r",
      "296\r",
      "297\r",
      "298\r",
      "299\r",
      "300\r",
      "301\r",
      "302\r",
      "303\r",
      "304\r",
      "305\r",
      "306\r",
      "307\r",
      "308\r",
      "309\r",
      "310\r",
      "311\r",
      "312\r",
      "313\r",
      "314\r",
      "315\r",
      "316\r",
      "317\r",
      "318\r",
      "319\r",
      "320\r",
      "321\r",
      "322\r",
      "323\r",
      "324\r",
      "325\r",
      "326\r",
      "327\r",
      "328\r",
      "329\r",
      "330\r",
      "331\r",
      "332\r",
      "333\r",
      "334\r",
      "335\r",
      "336\r",
      "337\r",
      "338\r",
      "339\r",
      "340\r",
      "341\r",
      "342\r",
      "343\r",
      "344\r",
      "345\r",
      "346\r",
      "347\r",
      "348\r",
      "349\r",
      "350\r",
      "351\r",
      "352\r",
      "353\r",
      "354\r",
      "355\r",
      "356\r",
      "357\r",
      "358\r",
      "359\r",
      "360\r",
      "361\r",
      "362\r",
      "363\r",
      "364\r",
      "365\r",
      "366\r",
      "367\r",
      "368\r",
      "369\r",
      "370\r",
      "371\r",
      "372\r",
      "373\r",
      "374\r",
      "375\r",
      "376\r",
      "377\r",
      "378\r",
      "379\r",
      "380\r",
      "381\r",
      "382\r",
      "383\r",
      "384\r",
      "385\r",
      "386\r",
      "387\r",
      "388\r",
      "389\r",
      "390\r",
      "391\r",
      "392\r",
      "393\r",
      "394\r",
      "395\r",
      "396\r",
      "397\r",
      "398\r",
      "399\r",
      "400\r",
      "401\r",
      "402\r",
      "403\r",
      "404\r",
      "405\r",
      "406\r",
      "407\r",
      "408\r",
      "409\r",
      "410\r",
      "411\r",
      "412\r",
      "413\r",
      "414\r",
      "415\r",
      "416\r",
      "417\r",
      "418\r",
      "419\r",
      "420\r",
      "421\r",
      "422\r",
      "423\r",
      "424\r",
      "425\r",
      "426\r",
      "427\r",
      "428\r",
      "429\r",
      "430\r",
      "431\r",
      "432\r",
      "433\r",
      "434\r",
      "435\r",
      "436\r",
      "437\r",
      "438\r",
      "439\r",
      "440\r",
      "441\r",
      "442\r",
      "443\r",
      "444\r",
      "445\r",
      "446\r",
      "447\r",
      "448\r",
      "449\r",
      "450\r",
      "451\r",
      "452\r",
      "453\r",
      "454\r",
      "455\r",
      "456\r",
      "457\r",
      "458\r",
      "459\r",
      "460\r",
      "461\r",
      "462\r",
      "463\r",
      "464\r",
      "465\r",
      "466\r",
      "467\r",
      "468\r",
      "469\r",
      "470\r",
      "471\r",
      "472\r",
      "473\r",
      "474\r",
      "475\r",
      "476\r",
      "477\r",
      "478\r",
      "479\r",
      "480\r",
      "481\r",
      "482\r",
      "483\r",
      "484\r",
      "485\r",
      "486\r",
      "487\r",
      "488\r",
      "489\r",
      "490\r",
      "491\r",
      "492\r",
      "493\r",
      "494\r",
      "495\r",
      "496\r",
      "497\r",
      "498\r",
      "499\r",
      "500\r",
      "501\r",
      "502\r",
      "503\r",
      "504\r",
      "505\r",
      "506\r",
      "507\r",
      "508\r",
      "509\r",
      "510\r",
      "511\r",
      "512\r",
      "513\r",
      "514\r",
      "515\r",
      "516\r",
      "517\r",
      "518\r",
      "519\r",
      "520\r",
      "521\r",
      "522\r",
      "523\r",
      "524\r",
      "525\r",
      "526\r",
      "527\r",
      "528\r",
      "529\r",
      "530\r",
      "531\r",
      "532\r",
      "533\r",
      "534\r",
      "535\r",
      "536\r",
      "537\r",
      "538\r",
      "539\r",
      "540\r",
      "541\r",
      "542\r",
      "543\r",
      "544\r",
      "545\r",
      "546\r",
      "547\r",
      "548\r",
      "549\r",
      "550\r",
      "551\r",
      "552\r",
      "553\r",
      "554\r",
      "555\r",
      "556\r",
      "557\r",
      "558\r",
      "559\r",
      "560\r",
      "561\r",
      "562\r",
      "563\r",
      "564\r",
      "565\r",
      "566\r",
      "567\r",
      "568\r",
      "569\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouyifan/.pyenv/versions/3.9.13/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185309\r"
     ]
    }
   ],
   "source": [
    "input_ids=[]\n",
    "attention_masks=[]\n",
    "\n",
    "sentences = dataf['post']\n",
    "print(\"Progress:\")\n",
    "for id, sent in enumerate(sentences):\n",
    "    print(id, end=\"\\r\")\n",
    "    bert_inp=bert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =64,pad_to_max_length = True,return_attention_mask = True)\n",
    "    input_ids.append(bert_inp['input_ids'])\n",
    "    attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "labels=np.array(dataf['EI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1669829655598,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "ywuCuf1Wks6S",
    "outputId": "309e67e1-8d6c-405d-8d85-d1fa92f70653"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185310, 185310, 185310)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids),len(attention_masks),len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82tmFtmpX-1M"
   },
   "source": [
    "## Saving and Loading Data into the pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1496,
     "status": "ok",
     "timestamp": 1669829686889,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "7JhOjHzJX-hA",
    "outputId": "5b5ae565-f794-44f8-a9cd-efae98f9c3a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the pickle file.....\n",
      "Pickle files saved as  ./data/bert_inp.pkl ./data/bert_mask.pkl ./data/bert_label.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Preparing the pickle file.....')\n",
    "\n",
    "pickle_inp_path='./data/bert_inp.pkl'\n",
    "pickle_mask_path='./data/bert_mask.pkl'\n",
    "pickle_label_path='./data/bert_label.pkl'\n",
    "\n",
    "pickle.dump((input_ids),open(pickle_inp_path,'wb'))\n",
    "pickle.dump((attention_masks),open(pickle_mask_path,'wb'))\n",
    "pickle.dump((labels),open(pickle_label_path,'wb'))\n",
    "\n",
    "\n",
    "print('Pickle files saved as ',pickle_inp_path,pickle_mask_path,pickle_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1669829701137,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "4YK3NHaLYC7v",
    "outputId": "f4ff6cc5-fb74-4b2f-8120-e818ebfc8660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved pickle files..\n",
      "Input shape (185310, 64) Attention mask shape (185310, 64) Input label shape (185310,)\n"
     ]
    }
   ],
   "source": [
    "print('Loading the saved pickle files..')\n",
    "\n",
    "input_ids=pickle.load(open(pickle_inp_path, 'rb'))\n",
    "attention_masks=pickle.load(open(pickle_mask_path, 'rb'))\n",
    "labels=pickle.load(open(pickle_label_path, 'rb'))\n",
    "\n",
    "print('Input shape {} Attention mask shape {} Input label shape {}'.format(input_ids.shape,attention_masks.shape,labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VC25uoYmBFV"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1669829707842,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "XbwAcXrvmChl",
    "outputId": "c0869858-3449-4f61-f56c-159634c37591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inp shape (148248, 64) Val input shape (37062, 64)\n",
      "Train label shape (148248,) Val label shape (37062,)\n",
      "Train attention mask shape (148248, 64) Val attention mask shape (37062, 64)\n"
     ]
    }
   ],
   "source": [
    "train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.2)\n",
    "\n",
    "print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jdo-wzmem3fS"
   },
   "source": [
    "## Training Setup\n",
    "- Loss\n",
    "- Optimizer\n",
    "- Other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 721,
     "status": "ok",
     "timestamp": 1669829807097,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "ylg7TmAim2-u",
    "outputId": "7e5ea407-6b02-4430-ba3e-c12ceed1e179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing model layer distilbert\n",
      "distilbert\n",
      "False\n",
      "Freezing model layer pre_classifier\n",
      "pre_classifier\n",
      "False\n",
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMai  multiple                 66362880  \n",
      " nLayer)                                                         \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,955,010\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 66,953,472\n",
      "_________________________________________________________________\n",
      "\n",
      "Bert Model None\n"
     ]
    }
   ],
   "source": [
    "log_dir='tensorboard_data/tb_bert'\n",
    "model_save_path='./models/bert_model.h5'\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "# Freeze pretrained layers\n",
    "for _layer in bert_model_EI.layers:\n",
    "    if _layer.name == 'distilbert' or _layer.name == 'pre_classifier':\n",
    "        print(f\"Freezing model layer {_layer.name}\")\n",
    "        _layer.trainable = False\n",
    "    print(_layer.name)\n",
    "    print(_layer.trainable)\n",
    "        \n",
    "print('\\nBert Model',bert_model_EI.summary())\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08)\n",
    "\n",
    "bert_model_EI.compile(loss=loss,optimizer=optimizer,metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGd3k24vnXuc"
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1669830752665,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "ee3T4Hjio_gL",
    "outputId": "21d5d438-6b7b-4835-c21d-3296e9179f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8564779918735524437\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 17493216351942409757\n",
      "physical_device_desc: \"device: 0, name: METAL, pci bus id: <undefined>\"\n",
      "xla_global_id: -1\n",
      "]\n",
      "\n",
      "\n",
      "\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 21:29:20.289131: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-30 21:29:20.289244: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-11-30 21:29:20.296012: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-30 21:29:20.296069: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Check Device\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(\"\\n\\n\")\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "executionInfo": {
     "elapsed": 282503,
     "status": "error",
     "timestamp": 1669830269296,
     "user": {
      "displayName": "Yifan Zhou",
      "userId": "08524730183451264072"
     },
     "user_tz": 300
    },
    "id": "FjsZ6kianZo4",
    "outputId": "0741897b-f03b-4f94-9d28-8b3de3f928c9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 21:29:23.559630: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-11-30 21:29:27.318599: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4633/4633 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.5190"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 21:35:21.306383: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4633/4633 [==============================] - 442s 94ms/step - loss: 0.6922 - accuracy: 0.5190 - val_loss: 0.6906 - val_accuracy: 0.5470\n",
      "Epoch 2/50\n",
      "4633/4633 [==============================] - 426s 92ms/step - loss: 0.6900 - accuracy: 0.5409 - val_loss: 0.6887 - val_accuracy: 0.5560\n",
      "Epoch 3/50\n",
      "4633/4633 [==============================] - 426s 92ms/step - loss: 0.6883 - accuracy: 0.5500 - val_loss: 0.6874 - val_accuracy: 0.5514\n",
      "Epoch 4/50\n",
      "4633/4633 [==============================] - 430s 93ms/step - loss: 0.6873 - accuracy: 0.5528 - val_loss: 0.6863 - val_accuracy: 0.5571\n",
      "Epoch 5/50\n",
      "4633/4633 [==============================] - 426s 92ms/step - loss: 0.6863 - accuracy: 0.5541 - val_loss: 0.6855 - val_accuracy: 0.5590\n",
      "Epoch 6/50\n",
      "4633/4633 [==============================] - 424s 92ms/step - loss: 0.6856 - accuracy: 0.5564 - val_loss: 0.6849 - val_accuracy: 0.5584\n",
      "Epoch 7/50\n",
      "4633/4633 [==============================] - 427s 92ms/step - loss: 0.6851 - accuracy: 0.5573 - val_loss: 0.6845 - val_accuracy: 0.5576\n",
      "Epoch 8/50\n",
      "4633/4633 [==============================] - 426s 92ms/step - loss: 0.6847 - accuracy: 0.5565 - val_loss: 0.6840 - val_accuracy: 0.5601\n",
      "Epoch 9/50\n",
      "4633/4633 [==============================] - 425s 92ms/step - loss: 0.6844 - accuracy: 0.5567 - val_loss: 0.6837 - val_accuracy: 0.5594\n",
      "Epoch 10/50\n",
      "4633/4633 [==============================] - 430s 93ms/step - loss: 0.6842 - accuracy: 0.5568 - val_loss: 0.6833 - val_accuracy: 0.5608\n",
      "Epoch 11/50\n",
      "4633/4633 [==============================] - 430s 93ms/step - loss: 0.6836 - accuracy: 0.5587 - val_loss: 0.6831 - val_accuracy: 0.5607\n",
      "Epoch 12/50\n",
      "4633/4633 [==============================] - 430s 93ms/step - loss: 0.6835 - accuracy: 0.5598 - val_loss: 0.6829 - val_accuracy: 0.5595\n",
      "Epoch 13/50\n",
      "4633/4633 [==============================] - 430s 93ms/step - loss: 0.6831 - accuracy: 0.5597 - val_loss: 0.6827 - val_accuracy: 0.5607\n",
      "Epoch 14/50\n",
      "4633/4633 [==============================] - 430s 93ms/step - loss: 0.6830 - accuracy: 0.5597 - val_loss: 0.6825 - val_accuracy: 0.5603\n",
      "Epoch 15/50\n",
      "4633/4633 [==============================] - 433s 93ms/step - loss: 0.6829 - accuracy: 0.5595 - val_loss: 0.6824 - val_accuracy: 0.5602\n",
      "Epoch 16/50\n",
      "4633/4633 [==============================] - 430s 93ms/step - loss: 0.6828 - accuracy: 0.5605 - val_loss: 0.6824 - val_accuracy: 0.5605\n",
      "Epoch 17/50\n",
      "4633/4633 [==============================] - 428s 92ms/step - loss: 0.6827 - accuracy: 0.5604 - val_loss: 0.6822 - val_accuracy: 0.5609\n",
      "Epoch 18/50\n",
      "4633/4633 [==============================] - 431s 93ms/step - loss: 0.6825 - accuracy: 0.5606 - val_loss: 0.6820 - val_accuracy: 0.5615\n",
      "Epoch 19/50\n",
      "4633/4633 [==============================] - 428s 92ms/step - loss: 0.6824 - accuracy: 0.5605 - val_loss: 0.6819 - val_accuracy: 0.5617\n",
      "Epoch 20/50\n",
      "4633/4633 [==============================] - 425s 92ms/step - loss: 0.6825 - accuracy: 0.5614 - val_loss: 0.6819 - val_accuracy: 0.5615\n",
      "Epoch 21/50\n",
      "4633/4633 [==============================] - 428s 92ms/step - loss: 0.6824 - accuracy: 0.5610 - val_loss: 0.6817 - val_accuracy: 0.5624\n",
      "Epoch 22/50\n",
      "4633/4633 [==============================] - 433s 93ms/step - loss: 0.6822 - accuracy: 0.5608 - val_loss: 0.6817 - val_accuracy: 0.5625\n",
      "Epoch 23/50\n",
      "4633/4633 [==============================] - 431s 93ms/step - loss: 0.6822 - accuracy: 0.5612 - val_loss: 0.6817 - val_accuracy: 0.5618\n",
      "Epoch 24/50\n",
      "4633/4633 [==============================] - 430s 93ms/step - loss: 0.6821 - accuracy: 0.5620 - val_loss: 0.6816 - val_accuracy: 0.5623\n",
      "Epoch 25/50\n",
      "4633/4633 [==============================] - 434s 94ms/step - loss: 0.6819 - accuracy: 0.5623 - val_loss: 0.6816 - val_accuracy: 0.5626\n",
      "Epoch 26/50\n",
      "4633/4633 [==============================] - 427s 92ms/step - loss: 0.6819 - accuracy: 0.5607 - val_loss: 0.6813 - val_accuracy: 0.5623\n",
      "Epoch 27/50\n",
      "4633/4633 [==============================] - 425s 92ms/step - loss: 0.6820 - accuracy: 0.5620 - val_loss: 0.6814 - val_accuracy: 0.5628\n",
      "Epoch 28/50\n",
      "4633/4633 [==============================] - 426s 92ms/step - loss: 0.6819 - accuracy: 0.5631 - val_loss: 0.6812 - val_accuracy: 0.5629\n",
      "Epoch 29/50\n",
      "4633/4633 [==============================] - 424s 92ms/step - loss: 0.6816 - accuracy: 0.5636 - val_loss: 0.6812 - val_accuracy: 0.5626\n",
      "Epoch 30/50\n",
      "4633/4633 [==============================] - 427s 92ms/step - loss: 0.6815 - accuracy: 0.5625 - val_loss: 0.6811 - val_accuracy: 0.5629\n",
      "Epoch 31/50\n",
      "4633/4633 [==============================] - 431s 93ms/step - loss: 0.6814 - accuracy: 0.5632 - val_loss: 0.6811 - val_accuracy: 0.5625\n",
      "Epoch 32/50\n",
      "4633/4633 [==============================] - 429s 93ms/step - loss: 0.6816 - accuracy: 0.5633 - val_loss: 0.6810 - val_accuracy: 0.5627\n",
      "Epoch 33/50\n",
      "4633/4633 [==============================] - 432s 93ms/step - loss: 0.6815 - accuracy: 0.5623 - val_loss: 0.6811 - val_accuracy: 0.5633\n",
      "Epoch 34/50\n",
      "4633/4633 [==============================] - 432s 93ms/step - loss: 0.6814 - accuracy: 0.5629 - val_loss: 0.6809 - val_accuracy: 0.5631\n",
      "Epoch 35/50\n",
      "4633/4633 [==============================] - 431s 93ms/step - loss: 0.6816 - accuracy: 0.5627 - val_loss: 0.6809 - val_accuracy: 0.5629\n",
      "Epoch 36/50\n",
      "4633/4633 [==============================] - 431s 93ms/step - loss: 0.6813 - accuracy: 0.5622 - val_loss: 0.6808 - val_accuracy: 0.5642\n",
      "Epoch 37/50\n",
      "4633/4633 [==============================] - 431s 93ms/step - loss: 0.6814 - accuracy: 0.5629 - val_loss: 0.6809 - val_accuracy: 0.5649\n",
      "Epoch 38/50\n",
      "4633/4633 [==============================] - 432s 93ms/step - loss: 0.6813 - accuracy: 0.5632 - val_loss: 0.6808 - val_accuracy: 0.5644\n",
      "Epoch 39/50\n",
      "4633/4633 [==============================] - 433s 94ms/step - loss: 0.6813 - accuracy: 0.5624 - val_loss: 0.6807 - val_accuracy: 0.5632\n",
      "Epoch 40/50\n",
      "4633/4633 [==============================] - 431s 93ms/step - loss: 0.6810 - accuracy: 0.5650 - val_loss: 0.6807 - val_accuracy: 0.5650\n",
      "Epoch 41/50\n",
      "4633/4633 [==============================] - 432s 93ms/step - loss: 0.6813 - accuracy: 0.5638 - val_loss: 0.6806 - val_accuracy: 0.5637\n",
      "Epoch 42/50\n",
      "4633/4633 [==============================] - 432s 93ms/step - loss: 0.6812 - accuracy: 0.5640 - val_loss: 0.6806 - val_accuracy: 0.5652\n",
      "Epoch 43/50\n",
      "4633/4633 [==============================] - 434s 94ms/step - loss: 0.6811 - accuracy: 0.5635 - val_loss: 0.6805 - val_accuracy: 0.5632\n",
      "Epoch 44/50\n",
      "4633/4633 [==============================] - 433s 93ms/step - loss: 0.6812 - accuracy: 0.5637 - val_loss: 0.6807 - val_accuracy: 0.5641\n",
      "Epoch 45/50\n",
      "4633/4633 [==============================] - 433s 93ms/step - loss: 0.6809 - accuracy: 0.5639 - val_loss: 0.6805 - val_accuracy: 0.5639\n",
      "Epoch 46/50\n",
      "4633/4633 [==============================] - 434s 94ms/step - loss: 0.6812 - accuracy: 0.5639 - val_loss: 0.6805 - val_accuracy: 0.5656\n",
      "Epoch 47/50\n",
      "4633/4633 [==============================] - 433s 94ms/step - loss: 0.6810 - accuracy: 0.5636 - val_loss: 0.6804 - val_accuracy: 0.5642\n",
      "Epoch 48/50\n",
      "4633/4633 [==============================] - 433s 94ms/step - loss: 0.6808 - accuracy: 0.5647 - val_loss: 0.6806 - val_accuracy: 0.5655\n",
      "Epoch 49/50\n",
      "4633/4633 [==============================] - 433s 93ms/step - loss: 0.6810 - accuracy: 0.5648 - val_loss: 0.6806 - val_accuracy: 0.5646\n",
      "Epoch 50/50\n",
      "4633/4633 [==============================] - 433s 94ms/step - loss: 0.6807 - accuracy: 0.5646 - val_loss: 0.6804 - val_accuracy: 0.5656\n"
     ]
    }
   ],
   "source": [
    "history=bert_model_EI.fit([train_inp,train_mask],train_label,batch_size=32,epochs=50,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RD3Hyq7Any1G"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wrFbkCtdn0TA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file tf_model.h5 from cache at /Users/zhouyifan/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tf_model.h5\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_117', 'classifier', 'pre_classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-12-01 09:19:09.184215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159/1159 [==============================] - 86s 73ms/step\n",
      "F1 score 0.5718375569928957\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.55      0.56     18476\n",
      "           1       0.56      0.58      0.57     18586\n",
      "\n",
      "    accuracy                           0.56     37062\n",
      "   macro avg       0.56      0.56      0.56     37062\n",
      "weighted avg       0.56      0.56      0.56     37062\n",
      "\n",
      "Training and saving built model.....\n"
     ]
    }
   ],
   "source": [
    "model_save_path='./models/bert_model.h5'\n",
    "\n",
    "trained_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=2)\n",
    "trained_model.compile(loss=loss,optimizer=optimizer, metrics=[metric])\n",
    "trained_model.load_weights(model_save_path)\n",
    "\n",
    "preds = trained_model.predict([val_inp,val_mask],batch_size=32)\n",
    "#pred_labels = preds.argmax(axis=1)\n",
    "pred_labels = np.argmax(preds.logits, axis=1)\n",
    "f1 = f1_score(val_label,pred_labels)\n",
    "print('F1 score',f1)\n",
    "print('Classification Report')\n",
    "print(classification_report(val_label,pred_labels,target_names=None))\n",
    "\n",
    "print('Training and saving built model.....')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMncS9Y9ykuufO84+892jEb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
