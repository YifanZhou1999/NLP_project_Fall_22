{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXJrIVqiHlED",
        "outputId": "64dbf6e9-cfe8-4c4a-d406-a0a840fea939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPmYzWBcIb-H",
        "outputId": "7f491c2b-c1e8-4451-a7a2-cf6a85ebff16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa21a5e0fb0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn import metrics\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "TYcaMHjw8KX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "df = pd.read_csv('/content/drive/My Drive/Project/dataset2.csv').dropna()\n",
        "total_words = 0\n",
        "for i in range(len(df['type'])):\n",
        "  try:\n",
        "    line = df['post'][i]\n",
        "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
        "    total_words += len(line.split())\n",
        "    if i < 5:\n",
        "      print(line)\n",
        "      print(total_words)\n",
        "  except:\n",
        "    continue\n",
        "print(total_words)\n",
        "print(total_words/len(df['type']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2mfCY0Z_dMI",
        "outputId": "afa6fbee-9fb0-4a4e-d517-b25671f66c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What has been the most lifechanging experience in your life\n",
            "10\n",
            "May the PerC Experience immerse you\n",
            "16\n",
            "Hello ENFJ7 Sorry to hear of your distress Its only natural for a relationship to not be perfection all the time in every moment of existence Try to figure the hard times as times of growth as\n",
            "53\n",
            "Welcome and stuff\n",
            "56\n",
            "Prozac wellbrutin at least thirty minutes of moving your legs and I dont mean moving them while sitting in your same desk chair weed in moderation maybe try edibles as a healthier alternative\n",
            "89\n",
            "10739789\n",
            "27.08490806334059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turn balanced datasets to pickle for easy access in the future"
      ],
      "metadata": {
        "id": "0tqOexlCNtFR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZMtSECZcz_l"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Project/balanced_EI_dataset.csv')\n",
        "for i in range(len(df['type'])):\n",
        "  if \"E\" in df['type'][i]:\n",
        "    df['type'][i] = 1\n",
        "  else:\n",
        "    df['type'][i] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDIMGGhnjmfe"
      },
      "outputs": [],
      "source": [
        "df.to_pickle(\"/content/drive/My Drive/Project/EIbinary.pkl\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RPIH-Qinj0fS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_pickle(\"/content/drive/My Drive/Project/EIbinary.pkl\") "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatize"
      ],
      "metadata": {
        "id": "vBqhLkOA8qE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    # line = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    line = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
        "    return ' '.join(map(str,line))\n",
        "\n",
        "df['post'] = df.post.apply(lemmatize_text)\n",
        "# df['post'] = df['post'].str.lower()"
      ],
      "metadata": {
        "id": "zWwWNdCsf1LT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traditional Models"
      ],
      "metadata": {
        "id": "KbDSkMQvA2ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split dataset to training and testing dataset"
      ],
      "metadata": {
        "id": "ERDn7R5EhPJE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FmfjtiaYc2Fd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['post'], df['type'], \n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "0b-VLcU2fGK5"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.astype('int')\n",
        "y_test = y_test.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use tf-idf weighted document-term matrix as features"
      ],
      "metadata": {
        "id": "EYmcoYmto2A5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "YasWoBCic9TE"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "X_train = tfidf.fit_transform(X_train)\n",
        "X_test = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdws1FOFdBjM",
        "outputId": "c8d6b91b-5fd1-45e9-cb40-3c5be529d6a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6214937850621494"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model1 = LogisticRegression(max_iter=2000)\n",
        "model1.fit(X_train, y_train)\n",
        "model1.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqfSK-ifhETH",
        "outputId": "8aa1d7e7-56dd-4fbb-93e5-bb6b9d420098"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6103013969860301"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "model2 = SGDClassifier()\n",
        "model2.fit(X_train, y_train)\n",
        "model2.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBGljP1YhGZi",
        "outputId": "02536c8d-c843-4319-b406-b355027b9d10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5620668793312067"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "model3 = Perceptron()\n",
        "model3.fit(X_train, y_train)\n",
        "model3.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYzh0JqKhcu0",
        "outputId": "e138b7a9-89a1-40de-dc30-65fcea37349e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6160350896491035"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model4 = MultinomialNB()\n",
        "model4.fit(X_train, y_train)\n",
        "model4.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wovSHLIFpDz5",
        "outputId": "905e2fd3-68d4-4af4-fdd2-4c001e4121eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6115388846111539"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "model5 = LinearSVC()\n",
        "model5.fit(X_train, y_train)\n",
        "model5.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WSt2VlPp4R_",
        "outputId": "66f08e4d-abba-422b-846e-a67467d8e634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5012787372126278\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import accuracy_score  \n",
        "\n",
        "model6 = KNeighborsRegressor(n_neighbors=3)\n",
        "model6.fit(X_train, y_train)\n",
        "prediction = model6.predict(X_test).astype('int')\n",
        "accuracy = accuracy_score(y_test, prediction)\n",
        "print(accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2RJEc4FiIlVY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}