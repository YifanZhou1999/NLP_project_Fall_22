{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PIYgmK7JGApG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669474923368,"user_tz":300,"elapsed":13061,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"e73495fe-7eb8-433f-adc1-494958ac5342"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ii069NmDFT8u","outputId":"eadab9c5-cb0f-4190-c848-63452ca22247","executionInfo":{"status":"ok","timestamp":1669474940109,"user_tz":300,"elapsed":16745,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 65.9 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 54.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 63.3 MB/s \n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 65.2 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 65.5 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.7.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"]}],"source":["!pip install transformers\n","!pip install datasets"]},{"cell_type":"code","source":["foldername= \"/content/drive/My Drive/nlpproject/\""],"metadata":{"id":"SO5mqsc8ZeJz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndair6dzFBl1"},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from transformers import DataCollatorWithPadding\n","from transformers import TrainingArguments, Trainer\n","from datasets import load_metric\n","import datetime\n","from torch import nn\n","from transformers import AutoConfig\n","from transformers import AutoModel\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_B13Be1POha"},"outputs":[],"source":["class CFG:\n","    str_now = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n","    basic_lr=1e-3\n","    train = True\n","    debug = False\n","    offline = False\n","    models_path = \"bert-base-uncased\"\n","    epochs = 50\n","    save_all_models = False\n","    apex = True\n","    print_freq = 20\n","    num_workers = 4\n","    model = \"bert-base-uncased\"\n","    loss_func = 'SmoothL1'\n","    scheduler = 'cosine'\n","    batch_scheduler = True\n","    num_cycles = 0.5\n","    num_warmup_steps = 0\n","    encoder_lr = 2e-5\n","    decoder_lr = 2e-5\n","    min_lr = 1e-6\n","    llrd = True\n","    layerwise_lr = 5e-5\n","    layerwise_lr_decay = 0.9\n","    layerwise_weight_decay = 0.01\n","    layerwise_adam_epsilon = 1e-6\n","    layerwise_use_bertadam = False\n","    #pooling\n","    pooling = 'mean' # mean, max, min, attention, weightedlayer\n","    layer_start = 4\n","    #init_weight\n","    init_weight = 'normal' # normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal\n","    #re-init\n","    reinit = True\n","    reinit_n = 1\n","    #adversarial\n","    fgm = False\n","    awp = False\n","    adv_lr = 1\n","    adv_eps = 0.2\n","    unscale = False\n","    eps = 1e-6\n","    betas = (0.9, 0.999)\n","    max_len = 100\n","    weight_decay = 0.01\n","    gradient_accumulation_steps = 1\n","    max_grad_norm = 1000\n","    target_cols = ['EI', 'SN', 'TF', 'JP']\n","    seed = 42\n","    cv_seed = 42\n","    n_fold = 4\n","    trn_fold = list(range(n_fold))\n","    batch_size = 2048\n","    n_targets = 4\n","    gpu_id = 0\n","    device = f'cuda:{gpu_id}'\n","cfg=CFG()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcMZxYMsFBl4","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["c5658a2ec6a54b3b846d6ff7e3652b44","ee8d2b53aabf491c9d0c0ed84d607a74","6774b7836cf64a99b1a33d8a8899b465","238fad680f3247d28d69e34aebe5760e","b32ccd3f91c843a1b11722b7caa873a4","d17cb89e8746490da9bac23037450ecc","af19cd940a0743d79039323c367a9577","bfe263b2b43f43a99db5349006e587d8","a7edcc6083374c8387a1ebdbd6b5f6e9","c3f46306e29c4d3184a60b43000aa376","50be031a213f4e66a5d9106c1d23093d","158ec57a68e741c28a5a856b7c6019ae","7d3fe2eca26f4a80973cc3d7cee0424e","438a6c35b74e41a4ac5ffd1dedf1affb","1a188518be694cb79a4c1d2d6a888cf6","7ef0b6d9bf984574b8859df254cb11ce","31a451bc83a54082bdf01a4b723b59e1","e98c7281f61840bea3d2ee5cb41ed116","ea51fcb99f3145da9a7ffdaea62ce8ee","53d98d6ee19b492ab7fde6442689020d","1e9285bdddae4ed89c46218cfc329e4f","a08b435dcf6044738306842c32bebe30","a71fdc6ac78448c2894fc6d4cadabe04","a3d35e172fed4f08b20ec7da163d36d5","c10d81292284494c9e4ef1b2e262ccfa","f9f5754edfa5452cbc340bfe1d178121","e4cc9b90ebc54b0fa7447375721a420d","7e920e3fc8bd4bcc8b39fd70b3a6dd70","6828d3ed1aa040d495773d3e18ce40dd","c7d5b2d760b5489599c3f8f1c0cb789e","4af5ffe27d324b52b74d87e99edc93e9","c40dd69099e443b38013aa70a05e0f1b","74cc8d3dd78e44f09751b4dfce91d7de"]},"executionInfo":{"status":"ok","timestamp":1669474948574,"user_tz":300,"elapsed":1364,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"1d520255-3584-4d1b-bf77-27d89c46a4bb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5658a2ec6a54b3b846d6ff7e3652b44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"158ec57a68e741c28a5a856b7c6019ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a71fdc6ac78448c2894fc6d4cadabe04"}},"metadata":{}}],"source":["\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification\n","tokenizer=BertTokenizer.from_pretrained(cfg.model)\n","#the dataset class for the first dataset, tokenized, and labeled\n","class Ds_EI(Dataset):\n","    def __init__(self, path, tokenizer, max_token_len=cfg.max_len):\n","        self.df = pd.read_csv(path).dropna()\n","        self.tokenizer=tokenizer\n","        self.max_token_len=max_token_len\n","        self.labelstrdicts={1:\"ESTJ\", 0:\"INFP\"}\n","        self.loc=0  #EI at index 0 in mbti\n","    def __len__(self):\n","        return (len(self.df))\n","    def __getitem__(self, index):\n","        item=self.df.iloc[index]\n","        text=item[\"post\"]\n","        type=item[\"type\"]\n","        labels=self.str2label(type)\n","        try:\n","          tokens=self.tokenizer(text,return_tensors=\"pt\", truncation=True, max_length=self.max_token_len, padding=\"max_length\")\n","        except:\n","          print(text)\n","          quit()\n","        return {\"input_ids\": torch.squeeze(tokens.input_ids), \"attention_mask\":torch.squeeze(tokens.attention_mask), \"labels\":labels}\n","    def str2label(self, string):\n","        letter=string[self.loc]\n","        if letter in \"ESTJ\":\n","            return 1\n","        else:\n","            return 0\n","    def label2str(self, label):\n","        return self.labelstrdicts[label][self.loc]\n","\n","class Ds_SN(Dataset):\n","    def __init__(self, path, tokenizer, max_token_len=cfg.max_len):\n","        self.df = pd.read_csv(path).dropna()\n","        self.tokenizer=tokenizer\n","        self.max_token_len=max_token_len\n","        self.labelstrdicts={1:\"ESTJ\", 0:\"INFP\"}\n","        self.loc=1  #EI at index 0 in mbti\n","    def __len__(self):\n","        return (len(self.df))\n","    def __getitem__(self, index):\n","        item=self.df.iloc[index]\n","        text=item[\"post\"]\n","        type=item[\"type\"]\n","        labels=self.str2label(type)\n","        try:\n","          tokens=self.tokenizer(text,return_tensors=\"pt\", truncation=True, max_length=self.max_token_len, padding=\"max_length\")\n","        except:\n","          print(text)\n","          quit()\n","        return {\"input_ids\": torch.squeeze(tokens.input_ids), \"attention_mask\":torch.squeeze(tokens.attention_mask), \"labels\":labels}\n","    def str2label(self, string):\n","        letter=string[self.loc]\n","        if letter in \"ESTJ\":\n","            return 1.\n","        else:\n","            return 0.\n","    def label2str(self, label):\n","        return self.labelstrdicts[label][self.loc]\n","\n","class Ds_TF(Dataset):\n","    def __init__(self, path, tokenizer, max_token_len=cfg.max_len):\n","        self.df = pd.read_csv(path).dropna()\n","        self.tokenizer=tokenizer\n","        self.max_token_len=max_token_len\n","        self.labelstrdicts={1:\"ESTJ\", 0:\"INFP\"}\n","        self.loc=2  #EI at index 0 in mbti\n","    def __len__(self):\n","        return (len(self.df))\n","    def __getitem__(self, index):\n","        item=self.df.iloc[index]\n","        text=item[\"post\"]\n","        type=item[\"type\"]\n","        labels=self.str2label(type)\n","        try:\n","          tokens=self.tokenizer(text,return_tensors=\"pt\", truncation=True, max_length=self.max_token_len, padding=\"max_length\")\n","        except:\n","          print(text)\n","          quit()\n","        return {\"input_ids\": torch.squeeze(tokens.input_ids), \"attention_mask\":torch.squeeze(tokens.attention_mask), \"labels\":labels}\n","    def str2label(self, string):\n","        letter=string[self.loc]\n","        if letter in \"ESTJ\":\n","            return 1.\n","        else:\n","            return 0.\n","    def label2str(self, label):\n","        return self.labelstrdicts[label][self.loc]\n","\n","class Ds_JP(Dataset):\n","    def __init__(self, path, tokenizer, max_token_len=cfg.max_len):\n","        self.df = pd.read_csv(path).dropna()\n","        self.tokenizer=tokenizer\n","        self.max_token_len=max_token_len\n","        self.labelstrdicts={1:\"ESTJ\", 0:\"INFP\"}\n","        self.loc=3  #EI at index 0 in mbti\n","    def __len__(self):\n","        return (len(self.df))\n","    def __getitem__(self, index):\n","        item=self.df.iloc[index]\n","        text=item[\"post\"]\n","        type=item[\"type\"]\n","        labels=self.str2label(type)\n","        try:\n","          tokens=self.tokenizer(text,return_tensors=\"pt\", truncation=True, max_length=self.max_token_len, padding=\"max_length\")\n","        except:\n","          print(text)\n","          quit()\n","        return {\"input_ids\": torch.squeeze(tokens.input_ids), \"attention_mask\":torch.squeeze(tokens.attention_mask), \"labels\":labels}\n","    def str2label(self, string):\n","        letter=string[self.loc]\n","        if letter in \"ESTJ\":\n","            return 1\n","        else:\n","            return 0\n","    def label2str(self, label):\n","        return self.labelstrdicts[label][self.loc]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddPb2H0pFBl7"},"outputs":[],"source":["path=foldername+\"dataset2.csv\"\n","#print(dataset[0])\n","data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n","def getdl(ds):\n","    total_len=len(ds)\n","    train_len=int(len(ds)*0.9)\n","    val_len=int((total_len-train_len)/2)\n","    test_len=total_len-train_len-val_len\n","    [train_ds, val_ds, test_ds]=torch.utils.data.random_split(ds, [train_len, val_len, test_len])\n","    #return (training dataloader, validation dataloader, test dataloader)\n","    return len(train_ds), len(val_ds), len(test_ds), DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=data_collator), DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=data_collator), DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=data_collator)\n","    #return DataLoader(ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=data_collator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Y7Vn2lUl15T"},"outputs":[],"source":["#NEED TO CHANGE WHEN SWITCH TASK\n","ds=Ds_EI(path, tokenizer)\n","len_train, len_val, len_test, train_dl_EI,val_dl_EI, test_dl_EI=getdl(ds)"]},{"cell_type":"code","source":["print(len(ds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ygOH1S-QkeN","executionInfo":{"status":"ok","timestamp":1669474978692,"user_tz":300,"elapsed":6,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"573bb06b-3bea-4327-f70a-92dc2f5b0a67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["396523\n"]}]},{"cell_type":"code","source":["for d in ds:\n","  "],"metadata":{"id":"KtelButdeW-Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(labels, outputs):\n","  answers=(torch.argmax(outputs, dim=1))\n","  allcorrect=torch.sum(answers==labels)\n","  return allcorrect"],"metadata":{"id":"yVvtsVnObQa4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Model(nn.Module):\n","\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n","        super(Model, self).__init__()\n","        self.hidden_dim = hidden_dim\n","\n","        #self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","\n","        # The LSTM takes word embeddings as inputs, and outputs hidden states\n","        # with dimensionality hidden_dim.\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n","\n","        # The linear layer that maps from hidden state space to tag space\n","        self.fc1= nn.Linear(hidden_dim, 128)\n","        self.fc2= nn.Linear(128, 32)\n","        self.fc3= nn.Linear(32, 8)\n","        self.fc_final= nn.Linear(8, 2)\n","    def forward(self, input_ids):\n","        o =  self.word_embeddings(input_ids)\n","        o,_= self.lstm(o)\n","        o=o[:,-1]\n","        o = self.fc1(o)\n","        o = self.fc2(o)\n","        o = self.fc3(o)\n","        o = self.fc_final(o)\n","        return o"],"metadata":{"id":"1EFcPfuA90hG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.optim import lr_scheduler\n","from torch.nn import CrossEntropyLoss\n","from torch import optim\n","from torch.optim import Adam\n","from tqdm.notebook import tqdm\n","def train(train_ds, eval_ds, model, epochs, cfg, type, lr, loss=None):\n","    if torch.cuda.is_available():  \n","        dev = \"cuda:0\" \n","    else:  \n","        dev = \"cpu\" \n","    device = torch.device(dev)\n","    model = model.to(device)\n","\n","    #weights=torch.tensor([1., 3.]).cuda()\n","    #criterion = nn.MSELoss()\n","    criterion = CrossEntropyLoss(weight=LABEL_RATIO)\n","\n","    criterion.to(device)\n","    #criterion = loss\n","    \n","    optimizer = Adam(model.parameters(), lr=lr)\n","    #optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n","    scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=500, eta_min=1e-15)\n","    #scheduler= optim.lr_scheduler.ExponentialLR(optimizer, 0.99, last_epoch=- 1, verbose=False)\n","        \n","    totalevalloss=0\n","    totalcorrect=0\n","    totaldata=0\n","    with torch.no_grad():\n","        model.eval()\n","        for batch in eval_ds:\n","            batch.to(device)\n","            blabels=batch[\"labels\"]\n","            outputs=model(input_ids=batch[\"input_ids\"])\n","            eloss=criterion(outputs, blabels).item()\n","            totalevalloss+=eloss\n","            totalcorrect+=evaluate(blabels, outputs)\n","            totaldata+=len(blabels)\n","    totalcorrect_rate=(totalcorrect/(totaldata))\n","    print(\"probability that our prediction of \", type, \" is correct: \", totalcorrect_rate)\n","    #print(f'Initial Val Loss: {totalevalloss / len(eval_ds): .3f} ' ) \n","    print(f'Initial Val Loss: {totalevalloss / len(eval_ds): .3f} | current lr: {scheduler.get_last_lr()}' ) \n","    \n","    for e in range(epochs):\n","        totaltrainloss=0\n","        totaltraincorrect=0\n","        totaltraindata=0\n","        for i,batch in enumerate(train_ds):\n","            model.train()\n","            optimizer.zero_grad()\n","            batch.to(device)\n","            labels=batch[\"labels\"]\n","            outputs=model(input_ids=batch[\"input_ids\"])\n","            bloss=criterion(outputs, labels)\n","            bloss.backward()\n","            optimizer.step()\n","            totaltrainloss+=bloss.item()\n","            totaltraincorrect+=evaluate(labels, outputs)\n","            totaltraindata+=len(labels)\n","        scheduler.step()\n","        totalevalloss=0\n","        totalcorrect=0\n","        totaldata=0\n","        with torch.no_grad():\n","            model.eval()\n","            for batch in eval_ds:\n","                batch.to(device)\n","                blabels=batch[\"labels\"]\n","                outputs=model(input_ids=batch[\"input_ids\"])\n","                eloss=criterion(outputs, blabels).item()\n","                totalevalloss+=eloss\n","                totalcorrect+=evaluate(blabels, outputs)\n","                totaldata+=len(blabels)\n","        totalcorrect_rate=(totalcorrect/(totaldata))\n","        totaltraincorrect_rate = (totaltraincorrect/(totaltraindata))\n","        print(\"probability that our prediction of \", type, \" is correct: \", totalcorrect_rate)\n","        print(\"probability that our prediction of \", type, \" is correct in training dataset: \", totaltraincorrect_rate)\n","        #print(f'Epoch: {e+ 1} | Train Loss: {totaltrainloss / len(train_ds): .8f} | Val Loss: {totalevalloss / len(eval_ds): .3f}' ) \n","        print(f'Epoch: {e+ 1} | Train Loss: {totaltrainloss / len(train_ds): .8f} | Val Loss: {totalevalloss / len(eval_ds): .8f} | current lr: {scheduler.get_last_lr()}' ) "],"metadata":{"id":"KYHzXvQlbvCJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model=Model(cfg, 0.2)\n","train(train_dl_EI, val_dl_EI, model, epochs=cfg.epochs, cfg=cfg, type=\"EI\", lr=1e-3, loss=None)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"id":"jcNfU20hb3aT","executionInfo":{"status":"error","timestamp":1669474978835,"user_tz":300,"elapsed":6,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"9594374e-cc6a-4c84-9da1-eff59176c936"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-3a44817ca80e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl_EI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl_EI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"EI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'vocab_size'"]}]},{"cell_type":"code","source":["if torch.cuda.is_available():  \n","    dev = \"cuda:0\" \n","else:  \n","    dev = \"cpu\" \n","device = torch.device(dev)\n","cpu=torch.device(\"cpu\")\n","features=[]\n","labels=[]\n","model.to(device)\n","with torch.no_grad():\n","    for i,batch in enumerate(dl_EI):\n","        print(i*cfg.batch_size)\n","        batch.to(device)\n","        #last_hidden_layers=model(input_ids=batch[\"input_ids\"],attention_mask=batch[\"attention_mask\"]).last_hidden_state[:,0]\n","        #last_hidden_layers.to(\"cpu\")\n","        #features.extend(last_hidden_layers)\n","        output=model(input_ids=batch[\"input_ids\"],attention_mask=batch[\"attention_mask\"])\n","        #print(output)\n","        output=output.last_hidden_state[:,0].cpu()\n","        #print(pooler_output[0])\n","        features.extend(output)\n","        l=batch[\"labels\"].to(\"cpu\")\n","        labels.extend(l)"],"metadata":{"id":"xyexQtxY1TE1"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[],"machine_shape":"hm"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"vscode":{"interpreter":{"hash":"47e86d731e077963188d400b641a1f5cee6401b89b8a1175acb1a082248e2517"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"c5658a2ec6a54b3b846d6ff7e3652b44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee8d2b53aabf491c9d0c0ed84d607a74","IPY_MODEL_6774b7836cf64a99b1a33d8a8899b465","IPY_MODEL_238fad680f3247d28d69e34aebe5760e"],"layout":"IPY_MODEL_b32ccd3f91c843a1b11722b7caa873a4"}},"ee8d2b53aabf491c9d0c0ed84d607a74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d17cb89e8746490da9bac23037450ecc","placeholder":"​","style":"IPY_MODEL_af19cd940a0743d79039323c367a9577","value":"Downloading: 100%"}},"6774b7836cf64a99b1a33d8a8899b465":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfe263b2b43f43a99db5349006e587d8","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7edcc6083374c8387a1ebdbd6b5f6e9","value":231508}},"238fad680f3247d28d69e34aebe5760e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3f46306e29c4d3184a60b43000aa376","placeholder":"​","style":"IPY_MODEL_50be031a213f4e66a5d9106c1d23093d","value":" 232k/232k [00:00&lt;00:00, 1.51MB/s]"}},"b32ccd3f91c843a1b11722b7caa873a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d17cb89e8746490da9bac23037450ecc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af19cd940a0743d79039323c367a9577":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfe263b2b43f43a99db5349006e587d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7edcc6083374c8387a1ebdbd6b5f6e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3f46306e29c4d3184a60b43000aa376":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50be031a213f4e66a5d9106c1d23093d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"158ec57a68e741c28a5a856b7c6019ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d3fe2eca26f4a80973cc3d7cee0424e","IPY_MODEL_438a6c35b74e41a4ac5ffd1dedf1affb","IPY_MODEL_1a188518be694cb79a4c1d2d6a888cf6"],"layout":"IPY_MODEL_7ef0b6d9bf984574b8859df254cb11ce"}},"7d3fe2eca26f4a80973cc3d7cee0424e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31a451bc83a54082bdf01a4b723b59e1","placeholder":"​","style":"IPY_MODEL_e98c7281f61840bea3d2ee5cb41ed116","value":"Downloading: 100%"}},"438a6c35b74e41a4ac5ffd1dedf1affb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea51fcb99f3145da9a7ffdaea62ce8ee","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53d98d6ee19b492ab7fde6442689020d","value":28}},"1a188518be694cb79a4c1d2d6a888cf6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e9285bdddae4ed89c46218cfc329e4f","placeholder":"​","style":"IPY_MODEL_a08b435dcf6044738306842c32bebe30","value":" 28.0/28.0 [00:00&lt;00:00, 931B/s]"}},"7ef0b6d9bf984574b8859df254cb11ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31a451bc83a54082bdf01a4b723b59e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e98c7281f61840bea3d2ee5cb41ed116":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea51fcb99f3145da9a7ffdaea62ce8ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53d98d6ee19b492ab7fde6442689020d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e9285bdddae4ed89c46218cfc329e4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a08b435dcf6044738306842c32bebe30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a71fdc6ac78448c2894fc6d4cadabe04":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a3d35e172fed4f08b20ec7da163d36d5","IPY_MODEL_c10d81292284494c9e4ef1b2e262ccfa","IPY_MODEL_f9f5754edfa5452cbc340bfe1d178121"],"layout":"IPY_MODEL_e4cc9b90ebc54b0fa7447375721a420d"}},"a3d35e172fed4f08b20ec7da163d36d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e920e3fc8bd4bcc8b39fd70b3a6dd70","placeholder":"​","style":"IPY_MODEL_6828d3ed1aa040d495773d3e18ce40dd","value":"Downloading: 100%"}},"c10d81292284494c9e4ef1b2e262ccfa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7d5b2d760b5489599c3f8f1c0cb789e","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4af5ffe27d324b52b74d87e99edc93e9","value":570}},"f9f5754edfa5452cbc340bfe1d178121":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c40dd69099e443b38013aa70a05e0f1b","placeholder":"​","style":"IPY_MODEL_74cc8d3dd78e44f09751b4dfce91d7de","value":" 570/570 [00:00&lt;00:00, 18.7kB/s]"}},"e4cc9b90ebc54b0fa7447375721a420d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e920e3fc8bd4bcc8b39fd70b3a6dd70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6828d3ed1aa040d495773d3e18ce40dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7d5b2d760b5489599c3f8f1c0cb789e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4af5ffe27d324b52b74d87e99edc93e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c40dd69099e443b38013aa70a05e0f1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74cc8d3dd78e44f09751b4dfce91d7de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}